{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nipype.interfaces import afni, fsl\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import re\n",
    "import getpass\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from nilearn import image, plotting\n",
    "import scipy.stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sqlite3\n",
    "from tabulate import tabulate\n",
    "from io import StringIO\n",
    "import getpass\n",
    "\n",
    "#Prime functions, can be choosen to run in the next cell\n",
    "def smooth_movavg(in_file, out_file, win_sec_duration, tr):\n",
    "\n",
    "  win = max(1, int(round(win_sec_duration / tr)))\n",
    "  \n",
    "  # Apply moving average\n",
    "  def moving_average_1d(x, win):\n",
    "      k = np.ones(win, dtype=float) / win\n",
    "      xpad = np.pad(x, (win//2, win-1-win//2), mode='edge')  # reduce edge shrinkage\n",
    "      return np.convolve(xpad, k, mode='valid')\n",
    "\n",
    "  img = nib.load(in_file)\n",
    "  data = img.get_fdata()   # X,Y,Z,T\n",
    "  T = data.shape[-1]\n",
    "  flat = data.reshape(-1, T)\n",
    "  sm = np.vstack([moving_average_1d(ts, win) for ts in flat]).reshape(data.shape)\n",
    "\n",
    "  nib.Nifti1Image(sm, img.affine, img.header).to_filename(out_file)\n",
    "  print(f\"Wrote: {out_file}  (tr={tr}s, window={win_sec_duration}s => {win} vols)\")\n",
    "def bruker_to_nifti(in_path, scan_number, out_file):\n",
    "\n",
    "    import os, glob, shutil, subprocess\n",
    "    from nipype.interfaces import afni\n",
    "\n",
    "    scan_dir = os.path.join(in_path, scan_number)\n",
    "    method_file = os.path.join(scan_dir, \"method\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Helper: safely collect only produced NIfTI files\n",
    "    # -------------------------------------------------------\n",
    "    def get_nifti_files(scan_number):\n",
    "        return [\n",
    "            f for f in glob.glob(f\"*{scan_number}*.nii*\")\n",
    "            if os.path.isfile(f)\n",
    "        ]\n",
    "\n",
    "    # ---------- 1) Run brkraw tonii ----------\n",
    "    cmd = [\"brkraw\", \"tonii\", f\"{in_path}/\", \"-s\", str(scan_number)]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    # ---------- 2) Detect echo count ----------\n",
    "    NoOfEchoImages = None\n",
    "    if os.path.exists(method_file):\n",
    "        with open(method_file) as f:\n",
    "            for line in f:\n",
    "                if \"PVM_NEchoImages=\" in line:\n",
    "                    echo_str = line.split(\"=\")[1].strip()\n",
    "                    try:\n",
    "                        NoOfEchoImages = int(echo_str)\n",
    "                    except:\n",
    "                        NoOfEchoImages = 1\n",
    "                    break\n",
    "\n",
    "    # ---------- 3) Collect produced NIfTI files ----------\n",
    "    src_files = get_nifti_files(scan_number)\n",
    "\n",
    "    if not src_files:\n",
    "        raise RuntimeError(\n",
    "            f\"No NIfTI files found after brkraw conversion for scan {scan_number}\"\n",
    "        )\n",
    "\n",
    "    # ---------- 4) Single echo OR unknown echo ----------\n",
    "    if NoOfEchoImages is None or NoOfEchoImages == 1:\n",
    "        # Just copy first detected nifti\n",
    "        shutil.copy(src_files[0], \"G1_cp.nii.gz\")\n",
    "\n",
    "    # ---------- 5) Multi-echo ----------\n",
    "    else:\n",
    "        merged_file = f\"{scan_number}_combined_images.nii.gz\"\n",
    "\n",
    "        # Merge all echoes\n",
    "        subprocess.run(\n",
    "            [\"fslmerge\", \"-t\", merged_file] + src_files,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        shutil.copy(merged_file, \"G1_cp.nii.gz\")\n",
    "\n",
    "    # ---------- 6) Fix orientation to LPI ----------\n",
    "    print(f\"{bcolors.NOTIFICATION}Fixing orientation to LPI{bcolors.ENDC}\")\n",
    "\n",
    "    resample = afni.Resample()\n",
    "    resample.inputs.in_file = \"G1_cp.nii.gz\"\n",
    "    resample.inputs.out_file = out_file\n",
    "    resample.inputs.orientation = \"LPI\"\n",
    "    resample.run()\n",
    "\n",
    "    # ---------- 7) Save NIfTI header info ----------\n",
    "    with open(\"NIFTI_file_header_info.txt\", \"w\") as out:\n",
    "        subprocess.run([\"fslhd\", out_file], stdout=out, check=True)\n",
    "\n",
    "    print_statement(\n",
    "        f\"[OK] Bruker → NIFTI workflow completed.\",\n",
    "        bcolors.OKGREEN\n",
    "    )\n",
    "def extract_middle_volume(in_file, reference_vol, out_file, size):\n",
    "  extract_vol = fsl.ExtractROI()\n",
    "  extract_vol.inputs.in_file=in_file \n",
    "  extract_vol.inputs.t_min=reference_vol \n",
    "  extract_vol.inputs.t_size=size \n",
    "  extract_vol.inputs.roi_file=out_file\n",
    "  extract_vol.run()\n",
    "\n",
    "  print(\"[OK] Intended Volumes extracted.\")\n",
    "  return out_file\n",
    "def motion_correction(reference_vol, input_vol, output_prefix):\n",
    "\n",
    "    # ---------- 1) 3dvolreg ----------\n",
    "    \n",
    "    volreg = afni.Volreg()  \n",
    "    volreg.inputs.in_file = input_vol\n",
    "    volreg.inputs.basefile = reference_vol\n",
    "    volreg.inputs.out_file = f\"{output_prefix}.nii.gz\"\n",
    "    volreg.inputs.oned_file = \"motion.1D\"\n",
    "    volreg.inputs.args = '-linear'\n",
    "    volreg.inputs.oned_matrix_save = \"mats\"\n",
    "    volreg.inputs.oned_matrix_save = \"rmsabs.1D\"\n",
    "    volreg.inputs.verbose = True\n",
    "    volreg.run()\n",
    "\n",
    "    print(\"[INFO] Running 3dvolreg…\")\n",
    "    return output_prefix\n",
    "def plot_motion_parameters(input_file):\n",
    "\n",
    "    # ---------- 4) Plot motion parameters ----------\n",
    "    print(\"[INFO] Creating motion plots…\")\n",
    "\n",
    "    # Translation plots\n",
    "    data = np.loadtxt(input_file)\n",
    "\n",
    "    # If your file HAS a header, use:\n",
    "    # data = np.loadtxt(\"your_file.1D\", comments=\"#\")\n",
    "\n",
    "    # X-axis (row index / timepoints)\n",
    "    x = np.arange(data.shape[0])\n",
    "\n",
    "    # -------- Plot 1: first 3 columns --------\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(3):\n",
    "        plt.plot(x, data[:, i], label=f\"Column {i+1}\")\n",
    "\n",
    "    plt.title(\"Rotation\")\n",
    "    plt.xlabel(\"Volume Number\")\n",
    "    plt.ylabel(\"Rotation in degrees\")\n",
    "    plt.legend([\"Pitch (x)\", \"Roll (y)\", \"Yaw (z)\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"motion_rotations.svg\", dpi=1200)\n",
    "    # -------- Plot 2: next 3 columns --------\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(3, 6):\n",
    "        plt.plot(x, data[:, i], label=f\"Column {i+1}\")\n",
    "\n",
    "    plt.title(\"Translation\")\n",
    "    plt.xlabel(\"Volume Number\")\n",
    "    plt.ylabel(\"Translation in mm\")\n",
    "    plt.legend([\"Read (x)\", \"Phase (y)\", \"Slice (z)\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"motion_translations.svg\", dpi=1200)\n",
    "def compute_mean_range(input_file, prefix, start_idx, end_idx):\n",
    "    \n",
    "    afni_cmd = [\"3dTstat\", \"-mean\", \"-prefix\", prefix, f\"{input_file}[{start_idx}..{end_idx}]\"]\n",
    "\n",
    "    print(\"[INFO] Running:\", \" \".join(afni_cmd))\n",
    "\n",
    "    subprocess.run(afni_cmd, check=True)\n",
    "    print_statement(\"[OK] Mean baseline image saved.\", bcolors.OKGREEN)\n",
    "def masking_file(input_file, mask_file, output_file):\n",
    "    \n",
    "    math = fsl.maths.ApplyMask()\n",
    "    math.inputs.in_file = input_file\n",
    "    math.inputs.mask_file = mask_file\n",
    "    math.inputs.out_file = output_file\n",
    "\n",
    "    math.run()\n",
    "\n",
    "    print_statement(f\"[OK] Masked file saved → {output_file}\", bcolors.OKGREEN)\n",
    "    return output_file\n",
    "def tSNR(input_file, output_file, reference_vol, size):\n",
    "  \n",
    "  extract_middle_volume(input_file, reference_vol, \"extracted_ts.nii.gz\", size)\n",
    "\n",
    "  mean = fsl.maths.MeanImage()\n",
    "  mean.inputs.in_file = \"extracted_ts.nii.gz\"\n",
    "  mean.inputs.out_file = \"mean_image.nii.gz\"\n",
    "  mean.run()\n",
    "\n",
    "  std = fsl.maths.StdImage()\n",
    "  std.inputs.in_file = \"extracted_ts.nii.gz\"\n",
    "  std.inputs.out_file = \"std_image.nii.gz\"\n",
    "  std.run()\n",
    "\n",
    "  tSNR = fsl.maths.BinaryMaths()\n",
    "  tSNR.inputs.in_file = \"mean_image.nii.gz\"\n",
    "  tSNR.inputs.operand_file = \"std_image.nii.gz\"\n",
    "  tSNR.inputs.operation = \"div\"\n",
    "  tSNR.inputs.out_file = output_file\n",
    "  tSNR.run()\n",
    "\n",
    "  print_statement(f\"[OK] tSNR file saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file\n",
    "def spatial_smoothing(input_file, output_file, fwhm):\n",
    "    cmd = [\"fslmaths\", input_file, \"-kernel\", \"gauss\", str(fwhm), \"-fmean\", output_file]\n",
    "\n",
    "    result = subprocess.run(cmd, check=True)\n",
    "    print(\"Smoothing completed successfully.\")\n",
    "def signal_change_map(signal_file, baseline_file, output_file):\n",
    "   \n",
    "  tmp_sub = \"tmp_signal_minus_baseline.nii.gz\"\n",
    "  tmp_div = \"tmp_psc_raw.nii.gz\"\n",
    "\n",
    "  sub = fsl.BinaryMaths()\n",
    "  sub.inputs.in_file = signal_file\n",
    "  sub.inputs.operand_file = baseline_file\n",
    "  sub.inputs.operation = \"sub\"\n",
    "  sub.inputs.out_file = tmp_sub\n",
    "  sub.run()\n",
    "\n",
    "  div = fsl.BinaryMaths()\n",
    "  div.inputs.in_file = tmp_sub\n",
    "  div.inputs.operand_file = baseline_file\n",
    "  div.inputs.operation = \"div\"\n",
    "  div.inputs.out_file = tmp_div\n",
    "  div.run()\n",
    "\n",
    "  mul = fsl.BinaryMaths()\n",
    "  mul.inputs.in_file = tmp_div\n",
    "  mul.inputs.operation = \"mul\"\n",
    "  mul.inputs.operand_value = 100\n",
    "  mul.inputs.out_file = output_file\n",
    "  mul.run()\n",
    "\n",
    "  os.remove(tmp_sub)\n",
    "  os.remove(tmp_div)\n",
    "\n",
    "  print_statement(f\"[OK] Percent Signal Change Map saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file\n",
    "def coregistration_afni(input_file1=None, input_file2=None, reference_file=None, output_file1=None, output_file2=None, estimate_affine=True, apply_affine=True, affine_mat=\"mean_func_struct_aligned.aff12.1D\"):\n",
    "\n",
    "  results = {}\n",
    "\n",
    "  # -------- STEP 1: Estimate affine --------\n",
    "  if estimate_affine:\n",
    "      if output_file1 is None:\n",
    "          raise ValueError(\"output_file1 must be provided when estimate_affine=True\")\n",
    "      if input_file1 is None:\n",
    "          raise ValueError(\"input_file1 must be provided when estimate_affine=True\")\n",
    "\n",
    "      coreg_wo_affine = afni.Allineate()\n",
    "      coreg_wo_affine.inputs.in_file = input_file1\n",
    "      coreg_wo_affine.inputs.reference = reference_file\n",
    "      coreg_wo_affine.inputs.out_matrix = affine_mat\n",
    "      coreg_wo_affine.inputs.cost = \"crU\"\n",
    "      coreg_wo_affine.inputs.two_pass = True\n",
    "      coreg_wo_affine.inputs.verbose = True\n",
    "      coreg_wo_affine.inputs.out_file = output_file1\n",
    "      coreg_wo_affine.inputs.out_param_file = \"params.1D\"\n",
    "      coreg_wo_affine.run()\n",
    "\n",
    "      print(f\"[OK] Affine estimated and saved → {affine_mat}\")\n",
    "      print(f\"[OK] Coregistered image (step 1) → {output_file1}\")\n",
    "\n",
    "      results[\"step1\"] = output_file1\n",
    "\n",
    "  # -------- STEP 2: Apply affine --------\n",
    "  if apply_affine:\n",
    "      if output_file2 is None:\n",
    "          raise ValueError(\"output_file2 must be provided when apply_affine=True\")\n",
    "      if input_file2 is None:\n",
    "          raise ValueError(\"input_file2 must be provided when apply_affine=True\")\n",
    "\n",
    "\n",
    "      coreg_with_affine = afni.Allineate()\n",
    "      coreg_with_affine.inputs.in_file = input_file2\n",
    "      coreg_with_affine.inputs.reference = reference_file\n",
    "      coreg_with_affine.inputs.in_matrix = affine_mat\n",
    "      coreg_with_affine.inputs.master = reference_file\n",
    "      coreg_with_affine.inputs.verbose = True\n",
    "      coreg_with_affine.inputs.final_interpolation = \"linear\"\n",
    "      coreg_with_affine.inputs.out_file = output_file2\n",
    "      coreg_with_affine.run()\n",
    "\n",
    "      print_statement(f\"[OK] Affine applied → {output_file2}\", bcolors.OKGREEN)\n",
    "      results[\"step2\"] = output_file2\n",
    "\n",
    "  return results\n",
    "def roi_analysis(func_in_file, roi_file, n_vols, tr, base_start, base_end, sig_start, sig_end):\n",
    "    print_statement(f\"Extracting time course for ROI: {roi_file}\", bcolors.NOTIFICATION)\n",
    "    output_file = f\"time_course_{roi_file.replace('.nii.gz', '.txt')}\"\n",
    "    time_course_extraction(roi_file, func_in_file, output_file)\n",
    "    print_statement(f\"[OK] Time course saved → {output_file}\", bcolors.OKGREEN)\n",
    "\n",
    "    #Creating Percent Signal Change graphs for each ROI\n",
    "    id_arr = list(range(0, n_vols, tr))\n",
    "    time_series = np.loadtxt(output_file)\n",
    "    # baseline = np.mean(time_series[base_start:base_end])\n",
    "    baseline = np.mean(time_series[base_start:base_end])\n",
    "    psc = ((time_series - baseline) / baseline) * 100\n",
    "    mean_signal = np.mean(psc[sig_start:sig_end])\n",
    "    print_statement(f\"[OK] Percent Signal Change calculated for ROI: {roi_file}\", bcolors.OKGREEN)\n",
    "    print(\"Time Series is:\", psc)\n",
    "    np.savetxt(f\"PSC_time_series_{roi_file.replace('.nii.gz', '.txt')}\", psc)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(id_arr, psc, label='Percent Signal Change')\n",
    "    plt.axvspan(base_start, base_end, color='green', alpha=0.3, label='Baseline Period')\n",
    "    plt.axvspan(sig_start, sig_end, color='blue', alpha=0.3, label='Signal Period')\n",
    "    plt.title(f'Percent Signal Change Time Series for {roi_file}')\n",
    "    plt.xlabel('Time Points (Volumes)')\n",
    "    plt.ylabel('MRI Signal Change (%)')\n",
    "    plt.set_ylim = (-2, 10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    graph_file = f\"PSC_Time_Series_{roi_file.replace('.nii.gz', '.svg')}\"\n",
    "    plt.savefig(graph_file, dpi=1200)\n",
    "    print_statement(f\"[OK] Percent Signal Change graph saved → {graph_file}\", bcolors.OKGREEN)   \n",
    "\n",
    "    return mean_signal\n",
    "def run_cmd(cmd):\n",
    "    \"\"\"Run shell command and return stdout.\"\"\"\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    return result.stdout.strip()\n",
    "def create_intensity_mask(input_img, output_mask, low_percentile, high_percentile):\n",
    "    \"\"\"\n",
    "    Create binary mask keeping voxels between given percentiles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_img : str\n",
    "        Path to 3D NIfTI image\n",
    "    output_mask : str\n",
    "        Output mask filename\n",
    "    low_percentile : float\n",
    "        Lower percentile (e.g., 20)\n",
    "    high_percentile : float\n",
    "        Upper percentile (e.g., 80)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Validate percentiles\n",
    "    # -------------------------\n",
    "    if not (0 <= low_percentile < high_percentile <= 100):\n",
    "        raise ValueError(\"Percentiles must satisfy: 0 <= low < high <= 100\")\n",
    "\n",
    "    # Get percentile thresholds\n",
    "    p_low = float(run_cmd([\"fslstats\", input_img, \"-l\", \"0.0001\", \"-P\", str(low_percentile)]))\n",
    "    p_high = float(run_cmd([\"fslstats\", input_img, \"-l\", \"0.0001\", \"-P\", str(high_percentile)]))\n",
    "\n",
    "\n",
    "    # Create binary mask\n",
    "    subprocess.run([\"fslmaths\", input_img, \"-thr\", str(p_low), \"-uthr\", str(p_high), \"-bin\", output_mask], check=True)\n",
    "\n",
    "    print(f\"Mask created: {output_mask}\")\n",
    "    print(f\"Thresholds used: {p_low:.3f} – {p_high:.3f}\")\n",
    "def make_3x3_roi_same_slice(ref_nii_path, center_phase, center_slice, center_read, out_path):\n",
    "    \"\"\"\n",
    "    Creates a 3x3 ROI (9 voxels) centered at (phase, slice, read),\n",
    "    keeping slice fixed, expanding +/-1 in phase and read.\n",
    "\n",
    "    Axis convention: data[phase, slice, read]\n",
    "    \"\"\"\n",
    "    ref_img = nib.load(ref_nii_path)\n",
    "    shape = ref_img.shape\n",
    "\n",
    "    roi = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "    p0, s0, r0 = int(center_phase), int(center_slice), int(center_read)\n",
    "\n",
    "    # Clip to bounds (if center is near edges, ROI may contain < 9 voxels)\n",
    "    p1 = max(p0 - 1, 0)\n",
    "    p2 = min(p0 + 1, shape[0] - 1)\n",
    "    r1 = max(r0 - 1, 0)\n",
    "    r2 = min(r0 + 1, shape[2] - 1)\n",
    "\n",
    "    if not (0 <= s0 < shape[1]):\n",
    "        raise ValueError(f\"center_slice {s0} out of bounds for shape {shape}\")\n",
    "\n",
    "    roi[p1:p2+1, s0, r1:r2+1] = 1\n",
    "\n",
    "    out_img = nib.Nifti1Image(roi, ref_img.affine, header=ref_img.header.copy())\n",
    "    out_img.set_data_dtype(np.uint8)\n",
    "    nib.save(out_img, out_path)\n",
    "\n",
    "    return out_path\n",
    "def save_roi_from_max(scm_path, hemisphere_mask_path, res):\n",
    "    # Decide output name from hemisphere mask filename\n",
    "    mask_name = os.path.basename(hemisphere_mask_path).lower()\n",
    "    out_name = \"roi_left.nii.gz\" if \"left\" in mask_name else \"roi_right.nii.gz\"\n",
    "\n",
    "    out_path = os.path.join(os.path.dirname(hemisphere_mask_path), out_name)\n",
    "\n",
    "    make_3x3_roi_same_slice(ref_nii_path=scm_path, center_phase=res[\"phase\"], center_slice=res[\"slice\"], center_read=res[\"read\"], out_path=out_path)\n",
    "    return out_path\n",
    "def max_voxel_in_mask(scm_path, mask_path, slice_pick=None, slice_pad=1):\n",
    "    \"\"\"\n",
    "    \n",
    "    Finds the voxel with highest SCM intensity inside a binary mask.\n",
    "\n",
    "    Axis convention assumed (same as your code):\n",
    "      scm_data[phase, slice, read]\n",
    "\n",
    "    slice_pick:\n",
    "      - None -> search all slices in the mask\n",
    "      - int  -> search only slice_pick ± slice_pad\n",
    "    \"\"\"\n",
    "    scm_img  = nib.load(scm_path)\n",
    "    scm_data = scm_img.get_fdata()\n",
    "\n",
    "    mask = nib.load(mask_path).get_fdata() > 0\n",
    "\n",
    "    if mask.shape != scm_data.shape:\n",
    "        raise ValueError(f\"Mask shape {mask.shape} != SCM shape {scm_data.shape}\")\n",
    "\n",
    "    # Optional: restrict to user-chosen slice ± pad\n",
    "    if slice_pick is not None:\n",
    "        sp = int(slice_pick)\n",
    "        pad = int(slice_pad)\n",
    "\n",
    "        coords = np.argwhere(mask)  # (phase, slice, read)\n",
    "        keep = (coords[:, 1] >= sp - pad) & (coords[:, 1] <= sp + pad)\n",
    "\n",
    "        coords = coords[keep]\n",
    "        if coords.size == 0:\n",
    "            return None\n",
    "\n",
    "        vals = scm_data[coords[:, 0], coords[:, 1], coords[:, 2]]\n",
    "        idx  = int(np.nanargmax(vals))\n",
    "        phase, slice_, read = coords[idx]\n",
    "        value = float(vals[idx])\n",
    "\n",
    "    else:\n",
    "        coords = np.argwhere(mask)          # (phase, slice, read)\n",
    "        vals   = scm_data[mask]\n",
    "        idx    = int(np.nanargmax(vals))\n",
    "        phase, slice_, read = coords[idx]\n",
    "        value  = float(vals[idx])\n",
    "\n",
    "    return {\"read\": int(read), \"phase\": int(phase), \"slice\": int(slice_), \"value\": value}\n",
    "\n",
    "\n",
    "# Helper functions, compulsory to run\n",
    "def time_course_extraction(roi_file, func_file, output_file):\n",
    "   \n",
    "    ts = fsl.ImageMeants()\n",
    "    ts.inputs.in_file = func_file\n",
    "    ts.inputs.mask = roi_file\n",
    "    ts.inputs.out_file = output_file\n",
    "\n",
    "    ts.run()\n",
    "def func_param_extract(scan_dir, export_env=True):\n",
    "\n",
    "    scan_dir = Path(scan_dir)\n",
    "    acqp_file = scan_dir / \"acqp\"\n",
    "    method_file = scan_dir / \"method\"\n",
    "    \n",
    "\n",
    "    if not acqp_file.exists() or not method_file.exists():\n",
    "        raise FileNotFoundError(\"acqp or method file not found\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Read files\n",
    "    # -----------------------------\n",
    "    acqp_text = acqp_file.read_text()\n",
    "    method_text = method_file.read_text()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Sequence name (ACQ_protocol_name)\n",
    "    # -----------------------------\n",
    "    seq_match = re.search(\n",
    "        r\"ACQ_protocol_name=\\(\\s*64\\s*\\)\\s*\\n\\s*<([^>]+)>\",\n",
    "        acqp_text\n",
    "    )\n",
    "    SequenceName = seq_match.group(1) if seq_match else None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract numeric parameters\n",
    "    # -----------------------------\n",
    "    def get_value(pattern, text, cast=int):\n",
    "        m = re.search(pattern, text)\n",
    "        return cast(m.group(1)) if m else None\n",
    "\n",
    "    NoOfRepetitions = get_value(r\"##\\$PVM_NRepetitions=\\s*(\\d+)\", method_text)\n",
    "    TotalScanTime = get_value(r\"##\\$PVM_ScanTime=\\s*(\\d+)\", method_text)\n",
    "\n",
    "    Baseline_TRs = get_value(r\"PreBaselineNum=\\s*(\\d+)\", method_text)\n",
    "    StimOn_TRs = get_value(r\"StimNum=\\s*(\\d+)\", method_text)\n",
    "    StimOff_TRs = get_value(r\"InterStimNum=\\s*(\\d+)\", method_text)\n",
    "    NoOfEpochs = get_value(r\"NEpochs=\\s*(\\d+)\", method_text)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Derived values\n",
    "    # -----------------------------\n",
    "    VolTR_msec = None\n",
    "    VolTR = None\n",
    "    MiddleVolume = None\n",
    "\n",
    "    if NoOfRepetitions and TotalScanTime:\n",
    "        VolTR_msec = TotalScanTime / NoOfRepetitions\n",
    "        VolTR = VolTR_msec / 1000\n",
    "        MiddleVolume = NoOfRepetitions / 2\n",
    "\n",
    "    # -----------------------------\n",
    "    # Pack results\n",
    "    # -----------------------------\n",
    "    params = {\n",
    "        \"SequenceName\": SequenceName,\n",
    "        \"NoOfRepetitions\": NoOfRepetitions,\n",
    "        \"TotalScanTime\": TotalScanTime,\n",
    "        \"VolTR_msec\": VolTR_msec,\n",
    "        \"VolTR\": VolTR,\n",
    "        \"Baseline_TRs\": Baseline_TRs,\n",
    "        \"StimOn_TRs\": StimOn_TRs,\n",
    "        \"StimOff_TRs\": StimOff_TRs,\n",
    "        \"NoOfEpochs\": NoOfEpochs,\n",
    "        \"MiddleVolume\": MiddleVolume,\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Export to environment (optional)\n",
    "    # -----------------------------\n",
    "    if export_env:\n",
    "        for k, v in params.items():\n",
    "            if v is not None:\n",
    "                os.environ[k] = str(v)\n",
    "\n",
    "    return params\n",
    "def extract_subject_id(scan_dir):\n",
    "    subject_file = Path(scan_dir) / \"subject\"\n",
    "\n",
    "    if not subject_file.exists():\n",
    "        raise FileNotFoundError(f\"'subject' file not found in {scan_dir}\")\n",
    "\n",
    "    with subject_file.open(\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"##$SUBJECT_id\"):\n",
    "            # The value is expected on the next line\n",
    "            value_line = lines[i + 1].strip()\n",
    "            return value_line.strip(\"<>\")\n",
    "\n",
    "    raise ValueError(\"##$SUBJECT_id not found in subject file\")\n",
    "def print_header(message, color):\n",
    "    line = \"*\" * 134   # same width everywhere\n",
    "    width = len(line)\n",
    "\n",
    "    print()\n",
    "    print(f\"{color}{line}{bcolors.ENDC}\")\n",
    "    print(f\"{color}{message.center(width)}{bcolors.ENDC}\")\n",
    "    print(f\"{color}{line}{bcolors.ENDC}\")\n",
    "    print()\n",
    "def print_statement(message, color):\n",
    "    print(f\"{color}{message}{bcolors.ENDC}\")\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    NOTIFICATION = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "def view_images(input_image, cmap=\"gray\"):\n",
    "    img = nib.load(input_image)\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Handle 4D vs 3D safely\n",
    "    if data.ndim == 4:\n",
    "        data = data[..., 0]   # take first volume\n",
    "    elif data.ndim != 3:\n",
    "        raise ValueError(f\"Unsupported data shape: {data.shape}\")\n",
    "\n",
    "    ny = data.shape[1]\n",
    "    cols = 8\n",
    "    rows = int(np.ceil(ny / cols))\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = np.atleast_1d(axes).flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < ny:\n",
    "            ax.imshow(data[:, i, :].T, cmap=cmap, origin=\"lower\")\n",
    "            ax.set_title(f\"y={i}\", fontsize=14)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def matching_nifti_files(directory, ref_shape):\n",
    "    matches = []\n",
    "\n",
    "    ref_xyz = tuple(ref_shape[:3])  # (64,16,64)\n",
    "    print(f\"Reference spatial shape: {ref_xyz}\")\n",
    "\n",
    "    for f in sorted(os.listdir(directory)):\n",
    "        if f.endswith((\".nii\", \".nii.gz\")):\n",
    "            try:\n",
    "                img = nib.load(os.path.join(directory, f))\n",
    "                img_xyz = tuple(img.shape[:3])\n",
    "\n",
    "                if img_xyz == ref_xyz:\n",
    "                    matches.append(f)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    \n",
    "    return matches\n",
    "def roi_analysis(func_in_file, roi_file, n_vols, tr, base_start, base_end, sig_start, sig_end):\n",
    "    print_statement(f\"Extracting time course for ROI: {roi_file}\", bcolors.NOTIFICATION)\n",
    "    output_file = f\"time_course_{roi_file.replace('.nii.gz', '.txt')}\"\n",
    "    time_course_extraction(roi_file, func_in_file, output_file)\n",
    "    print_statement(f\"[OK] Time course saved → {output_file}\", bcolors.OKGREEN)\n",
    "\n",
    "    #Creating Percent Signal Change graphs for each ROI\n",
    "    id_arr = list(range(0, n_vols, tr))\n",
    "    time_series = np.loadtxt(output_file)\n",
    "    # baseline = np.mean(time_series[base_start:base_end])\n",
    "    baseline = np.mean(time_series[base_start:base_end])\n",
    "    psc = ((time_series - baseline) / baseline) * 100\n",
    "    mean_signal = np.mean(psc[sig_start:sig_end])\n",
    "    print_statement(f\"[OK] Percent Signal Change calculated for ROI: {roi_file}\", bcolors.OKGREEN)\n",
    "    print(\"Time Series is:\", psc)\n",
    "    np.savetxt(f\"PSC_time_series_{roi_file.replace('.nii.gz', '.txt')}\", psc)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(id_arr, psc, label='Percent Signal Change')\n",
    "    plt.axvspan(base_start, base_end, color='green', alpha=0.3, label='Baseline Period')\n",
    "    plt.axvspan(sig_start, sig_end, color='blue', alpha=0.3, label='Signal Period')\n",
    "    plt.title(f'Percent Signal Change Time Series for {roi_file}')\n",
    "    plt.xlabel('Time Points (Volumes)')\n",
    "    plt.ylabel('MRI Signal Change (%)')\n",
    "    plt.set_ylim = (-2, 10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    graph_file = f\"PSC_Time_Series_{roi_file.replace('.nii.gz', '.svg')}\"\n",
    "    plt.savefig(graph_file, dpi=1200)\n",
    "    print_statement(f\"[OK] Percent Signal Change graph saved → {graph_file}\", bcolors.OKGREEN)   \n",
    "\n",
    "    return mean_signal\n",
    "def int_widget(value, desc):\n",
    "    return widgets.IntText(\n",
    "        value=value,\n",
    "        description=desc,\n",
    "        layout=INPUT_LAYOUT,\n",
    "        style={'description_width': DESC_WIDTH}\n",
    "    )\n",
    "def print_selected_pipeline_steps():\n",
    "    print(\"\\nPIPELINE STEP SELECTION SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for step in PIPELINE_STEPS:\n",
    "        key = step[\"key\"]\n",
    "        name = step[\"name\"]\n",
    "\n",
    "        if checkboxes[key].value:\n",
    "            print(f\"[✓] {name}\")\n",
    "        else:\n",
    "            print(f\"[ ] {name}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "def shrink_mask_xz_linewise(in_mask, out_mask, trim_x=3, trim_z=3):\n",
    "    img = nib.load(in_mask)\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    if data.ndim != 3:\n",
    "        raise ValueError(\"Input mask must be 3D\")\n",
    "\n",
    "    X, Y, Z = data.shape\n",
    "    mask = data.copy()\n",
    "\n",
    "    # Temporary mask after X-shrink\n",
    "    tmp_mask = np.zeros_like(mask, dtype=mask.dtype)\n",
    "    final_mask = np.zeros_like(mask, dtype=mask.dtype)\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 1 — Shrink along X for every (Y, Z)\n",
    "    # ==========================================================\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            line = mask[:, y, z]\n",
    "            idx = np.where(line > 0)[0]\n",
    "\n",
    "            if idx.size < 2 * trim_x + 1:\n",
    "                continue\n",
    "\n",
    "            x_min = idx.min() + trim_x\n",
    "            x_max = idx.max() - trim_x\n",
    "\n",
    "            tmp_mask[x_min:x_max + 1, y, z] = mask[x_min:x_max + 1, y, z]\n",
    "\n",
    "    # ==========================================================\n",
    "    # STEP 2 — Shrink along Z for every (Y, X)\n",
    "    # ==========================================================\n",
    "    for y in range(Y):\n",
    "        for x in range(X):\n",
    "            line = tmp_mask[x, y, :]\n",
    "            idx = np.where(line > 0)[0]\n",
    "\n",
    "            if idx.size < 2 * trim_z + 1:\n",
    "                continue\n",
    "\n",
    "            z_min = idx.min() + trim_z\n",
    "            z_max = idx.max() - trim_z\n",
    "\n",
    "            final_mask[x, y, z_min:z_max + 1] = \\\n",
    "                tmp_mask[x, y, z_min:z_max + 1]\n",
    "\n",
    "    nib.save(\n",
    "        nib.Nifti1Image(final_mask, img.affine, img.header),\n",
    "        out_mask\n",
    "    )\n",
    "\n",
    "    print(f\"[OK] Line-wise shrunk mask saved → {out_mask}\")\n",
    "def sanitize(value, na_text=\"NA\"):\n",
    "    \"\"\"\n",
    "    Convert undefined / empty values to 'NA'\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return na_text\n",
    "    if isinstance(value, str) and value.strip() == \"\":\n",
    "        return na_text\n",
    "    return value\n",
    "def safe_get(varname):\n",
    "    \"\"\"\n",
    "    Safely get a variable that may not exist.\n",
    "    \"\"\"\n",
    "    return locals().get(varname, globals().get(varname, None))\n",
    "def validate_analysis_inputs(fields):\n",
    "    \"\"\"\n",
    "    Logical validation only.\n",
    "    Missing values are allowed and stored as NA.\n",
    "    \"\"\"\n",
    "\n",
    "    if fields[\"temporal_res\"] not in (None, \"NA\"):\n",
    "        if fields[\"temporal_res\"] <= 0:\n",
    "            raise RuntimeError(\"Invalid temporal resolution (TR must be > 0)\")\n",
    "\n",
    "    if fields[\"window_duration\"] not in (None, \"NA\"):\n",
    "        if fields[\"window_duration\"] <= 0:\n",
    "            raise RuntimeError(\"Invalid window duration\")\n",
    "\n",
    "    if (\n",
    "        fields[\"start_idx_correlation\"] not in (None, \"NA\")\n",
    "        and fields[\"end_idx_correlation\"] not in (None, \"NA\")\n",
    "    ):\n",
    "        if fields[\"start_idx_correlation\"] >= fields[\"end_idx_correlation\"]:\n",
    "            raise RuntimeError(\"Invalid correlation window indices\")\n",
    "def is_step_enabled(step_key):\n",
    "    return checkboxes.get(step_key, None) and checkboxes[step_key].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_STEPS = [\n",
    "    {\"name\": \"Bruker → NIfTI\", \"key\": \"bruker_to_nifti\", \"func\": bruker_to_nifti, \"inputs\": [\"in_path\", \"scan_number\"], \"produces\": \"func_file\"},\n",
    "    {\"name\": \"Motion Correction\", \"key\": \"motion_correction\", \"func\": motion_correction, \"inputs\": [\"reference_vol\", \"func_file\", \"output_prefix\"], \"produces\": \"func_file\"},\n",
    "    {\"name\": \"Temporal Smoothing (MovAvg)\", \"key\": \"smooth_movavg\", \"func\": smooth_movavg, \"inputs\": [\"func_file\", \"out_file\", \"win_sec_duration\", \"tr\"], \"produces\": \"func_file\"},\n",
    "    {\"name\": \"Spatial Smoothing\", \"key\": \"spatial_smoothing\", \"func\": spatial_smoothing, \"inputs\": [\"func_file\", \"out_file\", \"fwhm\"], \"produces\": \"func_file\"},\n",
    "    {\"name\": \"Compute Mean Baseline\", \"key\": \"compute_mean_range\", \"func\": compute_mean_range, \"inputs\": [\"func_file\", \"prefix\", \"start_idx\", \"end_idx\"], \"produces\": \"baseline_file\"},\n",
    "    {\"name\": \"Masking\", \"key\": \"masking_file\", \"func\": masking_file, \"inputs\": [\"func_file\", \"mask_file\", \"out_file\"], \"produces\": \"func_file\"},\n",
    "    {\"name\": \"Temporal SNR Estimation\", \"key\": \"tSNR\", \"func\": tSNR, \"inputs\": [\"func_file\", \"out_file\", \"reference_vol\", \"size\"], \"produces\": \"tsnr_file\"},\n",
    "    {\"name\": \"Signal Change Map\", \"key\": \"signal_change_map\", \"func\": signal_change_map, \"inputs\": [\"func_file\", \"baseline_file\", \"out_file\"], \"produces\": \"psc_file\"},\n",
    "    {\"name\": \"ROI Analysis\", \"key\": \"roi_analysis\", \"func\": roi_analysis, \"inputs\": [\"func_in_file\", \"roi_file\", \"n_vols\", \"tr\", \"base_start\", \"base_end\", \"sig_start\", \"sig_end\"], \"produces\": \"roi_graphs\"},\n",
    "    {\"name\": \"Coregistration\", \"key\": \"coregistration_afni\", \"func\": coregistration_afni, \"inputs\": [\"input_file1\", \"input_file2\", \"reference_file\"], \"produces\": \"roi_graphs\"}]\n",
    "\n",
    "checkboxes = {}\n",
    "\n",
    "for step in PIPELINE_STEPS:\n",
    "    cb = widgets.Checkbox(value=True, description=step[\"name\"], indent=False)\n",
    "    checkboxes[step[\"key\"]] = cb\n",
    "\n",
    "box = widgets.Box(list(checkboxes.values()), layout=widgets.Layout(display=\"flex\", flex_flow=\"row wrap\", align_items=\"flex-start\", gap=\"10px\"))\n",
    "display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure what functionas are selected to run in the pipeline\n",
    "print_selected_pipeline_steps()\n",
    "\n",
    "## Choosing the raw data that needs to be analysed\n",
    "root_location = \"/Volumes/Extreme_Pro/fMRI\"\n",
    "selected_folder = FileChooser(root_location, layout=widgets.Layout(width='1080px'))\n",
    "selected_folder.show_only_dirs = True\n",
    "display(selected_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(selected_folder.selected_path)\n",
    "print(f\"Our Raw Data is located in the path {in_path}\")\n",
    "subject_id = extract_subject_id(in_path)\n",
    "\n",
    "# ---------- Common styles ----------\n",
    "INPUT_LAYOUT = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "ROW_LAYOUT = widgets.Layout(width=\"100%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\")\n",
    "DESC_WIDTH = \"220px\"\n",
    "\n",
    "# ---------- Widgets (KEEP REFERENCES) ----------\n",
    "func_scan_number_entered   = int_widget(10, \"Functional Scan:\")\n",
    "struct_scan_number_entered = int_widget(10, \"Structural Scan:\")\n",
    "win_entered         = int_widget(200, \"Window Duration (in vols):\")\n",
    "temp_smoothing_window = int_widget(60, \"Temporal Smoothing (in vols):\")\n",
    "\n",
    "row = widgets.HBox([func_scan_number_entered, struct_scan_number_entered, win_entered, temp_smoothing_window], layout=ROW_LAYOUT)\n",
    "display(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_scan_number = str(func_scan_number_entered.value)\n",
    "struct_scan_number = str(struct_scan_number_entered.value)\n",
    "win = str(win_entered.value)\n",
    "\n",
    "print_statement(f\"Subject under analysis is {subject_id} for Functional Scan Number {func_scan_number} and Structural Scan Number {struct_scan_number} with window size {win}\", bcolors.NOTIFICATION)\n",
    "\n",
    "# # Parameters extraction for structural and functional files\n",
    "\n",
    "params_struct = func_param_extract(Path(in_path) / struct_scan_number,export_env=True)\n",
    "sequence_name_struct = params_struct[\"SequenceName\"]\n",
    "\n",
    "params_func = func_param_extract(Path(in_path) / func_scan_number,export_env=True)\n",
    "sequence_name_func = params_func[\"SequenceName\"]\n",
    "\n",
    "\n",
    "# Setting up path for storing analysed data overall, strucutral data, functional data and processed functional data\n",
    "# Analysed data overall\n",
    "parts = list(in_path.parts)\n",
    "parts[parts.index(\"RawData\")] = \"AnalysedData\"\n",
    "analysed_base = Path(*parts).parent\n",
    "analysed_path = analysed_base / subject_id\n",
    "\n",
    "# Structural and Functional data\n",
    "analysed_struct_dir = Path(analysed_path) / f\"{struct_scan_number}{sequence_name_struct}\"\n",
    "analysed_func_dir = Path(analysed_path) / f\"{func_scan_number}{sequence_name_func}\"\n",
    "\n",
    "# processed functional data\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "user = getpass.getuser()\n",
    "folder_created = f\"{timestamp}_{user}\"\n",
    "analysis_dir = Path(analysed_path) / f\"{func_scan_number}{sequence_name_func}\" / folder_created\n",
    "analysis_dir.mkdir(parents=True, exist_ok=False)  # fail loudly if it already exists\n",
    "\n",
    "# src_dir = Path.cwd()\n",
    "\n",
    "# path for raw strucutral and functional data \n",
    "path_raw_struct = os.path.join(in_path, struct_scan_number)\n",
    "path_raw_func = os.path.join(in_path, func_scan_number)\n",
    "\n",
    "# Display of variables and paths in tabular form\n",
    "var_vals = [\n",
    "            ['Location of all Raw Data', 'root_location', root_location],\n",
    "            ['Location of Raw Data to be analysed', 'in_path', in_path],\n",
    "            ['Location of Raw Strcutural Data', 'path_raw_struct', path_raw_struct],\n",
    "            ['Location of Raw Functional Data', 'path_raw_func', path_raw_func],\n",
    "            ['Location of analysed structural data', 'analysed_struct_dir', analysed_struct_dir],\n",
    "            ['Location of analysed functional data', 'analysed_func_dir', analysed_func_dir],\n",
    "            ['Lcoation of final processed functional dta', 'analysis_dir', analysis_dir]\n",
    "            ]\n",
    "\n",
    "# pd.set_option('display.max_colwidth', 500)  # or 199\n",
    "df = pd.DataFrame(var_vals, columns=['Purpose', 'Variable Name', 'Value'], index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "print_statement(\"For your information: all generated files after processing stored in the directory will be utilising the below nomenclature:\", bcolors.NOTIFICATION)\n",
    "\n",
    "print(f\"After applying motion correction, file will be saved as mc_input_file\")\n",
    "print(f\"After applying temporal smoothing, file will be saved as ts_input_file\")\n",
    "print(f\"After applying spatial smoothing, file will be saved as sm_input_file\")\n",
    "print(f\"After applying temporal smoothing, file will be saved as ts_input_file\")\n",
    "print(f\"After applying temporal SNR, file will be saved as tsnr_input_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Converting Functional Data into NIFTI and Processing Functional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statement(f\"Analysed Data Path: {analysed_func_dir}\", bcolors.NOTIFICATION)\n",
    "analysed_func_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysed_func_dir)\n",
    "\n",
    "if is_step_enabled(\"bruker_to_nifti\"):\n",
    "    print_header(\"Converting Bruker to NIFTI: Functional Data\", bcolors.HEADER)\n",
    "\n",
    "    nifti_file = analysed_func_dir / \"func.nii.gz\"\n",
    "\n",
    "    if nifti_file.exists():\n",
    "        print_statement(\"NIfTI file already exists. Skipping conversion.\", bcolors.OKGREEN)\n",
    "    else:\n",
    "        bruker_to_nifti(in_path, func_scan_number, \"func.nii.gz\")\n",
    "\n",
    "    input_name_for_next_step = \"func\"\n",
    "    \n",
    "else:\n",
    "    print_statement(\"⏭️ Data Conversion Step not executed, May cause trouble in running further analysis\", bcolors.NOTIFICATION)\n",
    "\n",
    "input_name_for_next_step = \"func\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Generating Masks and Removing Border voxels from the handdrawn masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = int(params_func[\"VolTR\"])\n",
    "n_vols = params_func[\"NoOfRepetitions\"]\n",
    "middle_vol = str(int(n_vols / 2))\n",
    "\n",
    "extract_middle_volume(f\"{input_name_for_next_step}.nii.gz\", int(middle_vol), \"middle_vol.nii.gz\", 1)\n",
    "\n",
    "#Creating a mask to be applied on functional data using the mean baseline image\n",
    "\n",
    "if is_step_enabled(\"masking_file\"):\n",
    "    \n",
    "    mask_file= \"mask_mean_mc_func.nii.gz\"\n",
    "    mask_file_cannulas= \"mask_mean_mc_func_cannulas.nii.gz\"\n",
    "    \n",
    "    mask_file_shrunk = os.path.join(analysed_func_dir, \"mask_mean_mc_func_cleaned.nii.gz\")\n",
    "    mask_file_cannulas_shrunk = os.path.join(analysed_func_dir, \"mask_mean_mc_func_cannulas_cleaned.nii.gz\")\n",
    "    \n",
    "\n",
    "    if os.path.exists(mask_file):\n",
    "        print(f\"{bcolors.OKGREEN}Mask Image ({mask_file}) exists.{bcolors.ENDC}\")\n",
    "    else:\n",
    "        print(f\"{bcolors.FAIL}Mask Image does not exist. Please create the mask and save it as mask_mean_mc_func.nii.gz{bcolors.ENDC}\")\n",
    "        subprocess.run([\"fsleyes\", \"middle_vol.nii.gz\"])\n",
    "\n",
    "    if os.path.exists(mask_file_cannulas):\n",
    "        print(f\"{bcolors.OKGREEN}Mask Image including cannulas ({mask_file_cannulas}) exist.{bcolors.ENDC}\")\n",
    "    else:\n",
    "        print(f\"{bcolors.FAIL}Mask Image does not exist. Please create the mask that also includes cannulas and save it as mask_mean_mc_func_cannulas.nii.gz.{bcolors.ENDC}\")\n",
    "        shutil.copyfile(\"mask_mean_mc_func.nii.gz\", \"mask_mean_mc_func_cannulas.nii.gz\")\n",
    "        subprocess.run([\"fsleyes\", \"middle_vol.nii.gz\" , \"mask_mean_mc_func_cannulas.nii.gz\"])\n",
    "    \n",
    "    shrink_mask_xz_linewise(in_mask=mask_file, out_mask=mask_file_shrunk, trim_x=2, trim_z=2)\n",
    "    shrink_mask_xz_linewise(in_mask=mask_file_cannulas, out_mask=mask_file_cannulas_shrunk, trim_x=2, trim_z=2)\n",
    "\n",
    "else:\n",
    "    print_statement(\"⏭️ Masks not generated, will not get cleaned data in further pipeline\", bcolors.NOTIFICATION)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Applying Motion Correction in Raw Functional Data and Plotting Motion Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled(\"motion_correction\"):\n",
    "    print_header(\"Applying Motion Correction on raw functional data and plotting motion parameters\", bcolors.HEADER)\n",
    "\n",
    "    if os.path.exists(\"mc_func.nii.gz\"):\n",
    "        print(f\"{bcolors.OKGREEN}Motion Corrected functional data exists. Skipping motion correction.{bcolors.ENDC}\")\n",
    "    else:\n",
    "        motion_correction(\"middle_vol.nii.gz\", f\"{input_name_for_next_step}.nii.gz\", output_prefix=f\"mc_{input_name_for_next_step}\")\n",
    "    \n",
    "        \n",
    "    #Display of the motion corrected image and motion corrected graphs\n",
    "    input_name_for_next_step = f\"mc_{input_name_for_next_step}\"\n",
    "    view_images(\"mc_func.nii.gz\", cmap=\"gray\")\n",
    "    plot_motion_parameters(\"motion.1D\")    \n",
    "else:\n",
    "    print_statement(\"⏭️ Motion Correction not executed\", bcolors.NOTIFICATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Move into further subdirectory within Analysed Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statement(f\"Analysed Data Path Final: {analysis_dir}\", bcolors.NOTIFICATION)\n",
    "analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysis_dir)\n",
    "\n",
    "mask_file = os.path.join(analysed_func_dir, \"mask_mean_mc_func.nii.gz\")\n",
    "mask_file_cannulas = os.path.join(analysed_func_dir, \"mask_mean_mc_func_cannulas.nii.gz\")\n",
    "\n",
    "shutil.copyfile(f\"../{input_name_for_next_step}.nii.gz\", f\"{input_name_for_next_step}.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Selecting Start indices for both: Baseline and Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fsleyes to view the temporally smoothed motion corrected functional data\n",
    "print_statement(\"Choose your baseline and signal volumes from the temporally smoothed motion corrected functional data.\", bcolors.NOTIFICATION)\n",
    "subprocess.run([\"fsleyes\", f\"{input_name_for_next_step}.nii.gz\"])\n",
    "\n",
    "# ---------- Common styling ----------\n",
    "input_layout = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "label_style = {'description_width': '410px'}\n",
    "\n",
    "# ---------- Widgets ----------\n",
    "base_start_idx = widgets.IntText(value=400, description=\"Baseline Start Index:\", layout=input_layout, style=label_style)\n",
    "sig_start_idx = widgets.IntText(value=10, description=\"Signal Start Index:\", layout=input_layout, style=label_style)\n",
    "\n",
    "for w in [base_start_idx, sig_start_idx]:\n",
    "    w.style.description_width = \"180px\"\n",
    "\n",
    "# ---------- Container ----------\n",
    "row = widgets.HBox([base_start_idx, sig_start_idx],\n",
    "    layout=widgets.Layout(width=\"40%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\"))\n",
    "\n",
    "row.layout.background_color = \"#1e1e1e\"\n",
    "row.layout.border = \"3px solid #444\"\n",
    "\n",
    "display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_start = int(base_start_idx.value)\n",
    "sig_start  = int(sig_start_idx.value)\n",
    "base_end   = base_start + int(win_entered.value)\n",
    "sig_end   = sig_start + int(win_entered.value)\n",
    "\n",
    "print_statement(f\"Your baseline window selected is: {base_start}_to_{base_end}\", bcolors.OKGREEN)\n",
    "print_statement(f\"Your signal window selected is: {sig_start}_to_{sig_end}\", bcolors.OKGREEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Apply Spatial Smoothing and Generating Signal Change Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name_for_next_step = \"mc_func\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_path = Path(\"/Volumes/Extreme_Pro/fMRI/AnalysedData/Project_SeroAVATar_NJ_KR/Project2_Sero_AAV/RGRO_260128_0224_RN_SD_393/20functionalEPI\")\n",
    "# cleaned_file_path = Path(\"/Volumes/Extreme_Pro/fMRI/AnalysedData/Project_SeroAVATar_NJ_KR/Project2_Sero_AAV/RGRO_260128_0224_RN_SD_393/20functionalEPI/2026_02_10_093806_njain\")\n",
    "\n",
    "motion_corrected_file = \"mc_func.nii.gz\"\n",
    "\n",
    "print(f\"{input_name_for_next_step}.nii.gz\")\n",
    "\n",
    "## Currently based on the previous results, one eee\n",
    "if is_step_enabled(\"spatial_smoothing\"):\n",
    "    print_header(\"Applying Spatial Smoothing on motion corrected functional data\", bcolors.HEADER)\n",
    "    spatial_smoothing(f\"{input_name_for_next_step}.nii.gz\", f\"sm_{input_name_for_next_step}.nii.gz\", 0.297)\n",
    "    input_name_for_next_step = f\"sm_{input_name_for_next_step}\"\n",
    "else: \n",
    "    print_statement(\"⏭️ Spatial Smoothing not executed, will not get smoothed data in further pipeline\", bcolors.NOTIFICATION)\n",
    "    \n",
    "compute_mean_range(input_file=f\"{input_name_for_next_step}.nii.gz\", prefix=f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", start_idx=base_start, end_idx=base_end)\n",
    "compute_mean_range(input_file=f\"{input_name_for_next_step}.nii.gz\", prefix=f\"mean_signal_image_{sig_start}_to_{sig_end}.nii.gz\", start_idx=sig_start, end_idx=sig_end)\n",
    "\n",
    "signal_change_map(f\"mean_signal_image_{sig_start}_to_{sig_end}.nii.gz\", f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", f\"scm_from_sm_{input_name_for_next_step}.nii.gz\") # Creating SCM image\n",
    "signal_change_map(f\"{input_name_for_next_step}.nii.gz\", f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", f\"scm_timeseries_from_sm_{input_name_for_next_step}.nii.gz\") # Creating Signal Change Time Series\n",
    "\n",
    "\n",
    "compute_mean_range(motion_corrected_file, \"mean_mc_func.nii.gz\", 200, 500)\n",
    "masking_file(\"mean_mc_func.nii.gz\", mask_file_shrunk, \"cleaned_shrunk_mean_mc_func.nii.gz\")\n",
    "masking_file(\"mean_mc_func.nii.gz\", mask_file, \"cleaned_mean_mc_func.nii.gz\")\n",
    "\n",
    "# Create intensity mask based for the functional image\n",
    "create_intensity_mask(\"cleaned_shrunk_mean_mc_func.nii.gz\", \"mask_thresholded.nii.gz\", 15, 80)\n",
    "final_mask_used = os.path.join(analysis_dir, \"mask_thresholded.nii.gz\")\n",
    "\n",
    "\n",
    "if is_step_enabled(\"masking_file\"):\n",
    "    print_header(\"Applying Mask on motion corrected functional data\", bcolors.HEADER)\n",
    "    masking_file(f\"scm_from_sm_{input_name_for_next_step}.nii.gz\", final_mask_used, f\"clean_thresh_scm_from_sm_{input_name_for_next_step}.nii.gz\")\n",
    "    masking_file(f\"scm_from_sm_{input_name_for_next_step}.nii.gz\", mask_file_shrunk, f\"clean_shrunk_scm_from_sm_{input_name_for_next_step}.nii.gz\")\n",
    "    masking_file(f\"scm_from_sm_{input_name_for_next_step}.nii.gz\", mask_file, f\"cleaned_scm_from_sm_{input_name_for_next_step}.nii.gz\")\n",
    "\n",
    "    scm = f\"cleaned_scm_from_sm_{input_name_for_next_step}.nii.gz\"\n",
    "else:\n",
    "    print_statement(\"⏭️ Masking not executed, will not get cleaned data in further pipeline\", bcolors.NOTIFICATION)\n",
    "\n",
    "\n",
    "input_file_for_coreg = analysis_dir / \"cleaned_mean_mc_func.nii.gz\"\n",
    "scm_for_coreg = analysis_dir / f\"cleaned_scm_from_sm_{input_name_for_next_step}.nii.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Converting Structural Data into NIFTI and Processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statement(f\"Analysed Data Path: {analysed_struct_dir}\", bcolors.NOTIFICATION)\n",
    "analysed_struct_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysed_struct_dir)\n",
    "\n",
    "if is_step_enabled(\"bruker_to_nifti\"):\n",
    "    print_header(\"Converting Bruker to NIFTI: Structural Data\", bcolors.HEADER)\n",
    "\n",
    "    nifti_file = analysed_struct_dir / \"struct.nii.gz\"\n",
    "    if nifti_file.exists():\n",
    "        print_statement(\"NIfTI file already exists. Skipping conversion.\", bcolors.OKGREEN)\n",
    "    else:\n",
    "        bruker_to_nifti(in_path, struct_scan_number, \"struct.nii.gz\")\n",
    "\n",
    "else:\n",
    "    print_statement(\"⏭️ Data Conversion Step not executed, May cause trouble in running further analysis\", bcolors.NOTIFICATION)\n",
    "\n",
    "\n",
    "#Cleaning the structural image by masking it with a manually created mask\n",
    "\n",
    "if is_step_enabled(\"masking_file\"):\n",
    "    print_statement(\"Cleaning the structural image by manually creating mask\", bcolors.NOTIFICATION)\n",
    "    \n",
    "    if os.path.exists(\"cleaned_struct.nii.gz\"):\n",
    "        print_statement(\"Structural Image for Coregistration exists.\", bcolors.OKGREEN)\n",
    "    else:\n",
    "        print_statement(\"Please create a mask for the structural image and save it as mask_struct.nii.gz\", bcolors.NOTIFICATION)\n",
    "        subprocess.run([\"fsleyes\", \"struct.nii.gz\", os.path.join(analysed_func_dir, \"middle_vol.nii.gz\")])\n",
    "        masking_file(\"struct.nii.gz\", \"mask_struct.nii.gz\", \"cleaned_struct.nii.gz\")\n",
    "\n",
    "    structural_file_for_coregistration = os.path.join(analysed_struct_dir, \"cleaned_struct.nii.gz\")    \n",
    "    view_images(\"cleaned_struct.nii.gz\", cmap=\"gray\")\n",
    "    \n",
    "    #Further shrinking the mask for structural image to get better coregistration results as structural image has high spatial resolution than functional image\n",
    "    \n",
    "\n",
    "else:\n",
    "    print_statement(\"⏭️ Masks not generated, will not get cleaned data in further pipeline\", bcolors.NOTIFICATION)    \n",
    "    structural_file_for_coregistration = os.path.join(analysed_struct_dir, \"struct.nii.gz\")    \n",
    "    view_images(\"struct.nii.gz\", cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_statement(f\"Analysed Data Path Final: {analysis_dir}\", bcolors.NOTIFICATION)\n",
    "analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysis_dir)\n",
    "\n",
    "coregistration_afni(input_file_for_coreg, scm_for_coreg, structural_file_for_coregistration, output_file1=\"mean_func_struct_aligned.nii.gz\", output_file2=\"signal_change_map_coregistered_structural_space.nii.gz\", estimate_affine=True, apply_affine=True, affine_mat=\"mean_func_struct_aligned.aff12.1D\") # Estimating affnine and applying it to SCM\n",
    "\n",
    "\n",
    "create_intensity_mask(structural_file_for_coregistration, \"struct_mask_thresholded.nii.gz\", 15, 80)\n",
    "struct_final_mask_used = os.path.join(analysis_dir, \"struct_mask_thresholded.nii.gz\")\n",
    "shrink_mask_xz_linewise(in_mask=\"struct_mask_thresholded.nii.gz\", out_mask=\"struct_mask_thresholded_shrunk.nii.gz\", trim_x=2, trim_z=2)  \n",
    "masking_file(\"signal_change_map_coregistered_structural_space.nii.gz\", \"struct_mask_thresholded_shrunk.nii.gz\", \"cleaned_signal_change_map_coregistered_structural_space.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# ROI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = nib.load(mask_file_shrunk).get_fdata().astype(bool)\n",
    "func = nib.load(\"cleaned_mean_mc_func.nii.gz\").get_fdata().astype(bool)\n",
    "\n",
    "\n",
    "voxel_indices_func = np.column_stack(np.where(func))\n",
    "voxel_indices_mask = np.column_stack(np.where(mask))\n",
    "\n",
    "\n",
    "df_indices = pd.DataFrame(voxel_indices_mask)\n",
    "# display(df_indices)\n",
    "\n",
    "display(df_indices.columns)\n",
    "# display(df_indices)\n",
    "\n",
    "voxel_indices_func = np.column_stack(np.where(func))\n",
    "voxel_indices_mask = np.column_stack(np.where(mask))\n",
    "\n",
    "df_indices = pd.DataFrame(voxel_indices_mask)\n",
    "df_indices.columns = [\"read\", \"slice\", \"phase\"]\n",
    "\n",
    "display(df_indices.columns)\n",
    "display(df_indices)\n",
    "\n",
    "read  = df_indices[\"read\"].to_numpy()\n",
    "phase = df_indices[\"phase\"].to_numpy()\n",
    "slice = df_indices[\"slice\"].to_numpy()\n",
    "\n",
    "read_min = int(read.min())\n",
    "read_max = int(read.max())\n",
    "\n",
    "phase_min = int(phase.min())\n",
    "phase_max = int(phase.max())\n",
    "\n",
    "slice_min = int(slice.min())\n",
    "slice_max = int(slice.max())\n",
    "\n",
    "\n",
    "display(f\"Range of mask in Read dim: {read_min} to {read_max}\")\n",
    "display(f\"Range of mask in Phase dim: {phase_min} to {phase_max}\")\n",
    "display(f\"Range of mask in Slice dim: {slice_min} to {slice_max}\")\n",
    "\n",
    "center = np.array([(read_min  + read_max)  // 2, (slice_min + slice_max) // 2, (phase_min + phase_max) // 2])\n",
    "\n",
    "# find closest mask voxel\n",
    "voxels = voxel_indices_mask\n",
    "dists = np.linalg.norm(voxels - center, axis=1)\n",
    "mid_val_read, mid_val_slice, mid_val_phase = voxels[np.argmin(dists)]\n",
    "\n",
    "print(mid_val_read, mid_val_slice, mid_val_phase)\n",
    "\n",
    "\n",
    "hemisphere_right = df_indices[(df_indices['read'] < read_max) & (df_indices['read'] > mid_val_read) & (df_indices['phase'] < phase_max) & (df_indices['phase'] > phase_min)]\n",
    "hemisphere_left = df_indices[(df_indices['read'] > read_min) & (df_indices['read'] < mid_val_read) & (df_indices['phase'] < phase_max) & (df_indices['phase'] > phase_min)]\n",
    "\n",
    "def create_binary_mask(coords, shape):\n",
    "    binary_mask = np.zeros(shape, dtype=np.uint8)\n",
    "    coords = np.array(coords, dtype=int)\n",
    "    binary_mask[coords[:, 0], coords[:, 1], coords[:, 2]] = 1\n",
    "    return binary_mask\n",
    "\n",
    "mask_img = nib.load(mask_file_shrunk)\n",
    "mask_shape = mask_img.shape\n",
    "affine = mask_img.affine\n",
    "\n",
    "mask_hemisphere_right = create_binary_mask(hemisphere_right, mask_shape)\n",
    "mask_hemisphere_left = create_binary_mask(hemisphere_left, mask_shape)\n",
    "\n",
    "nib.save(nib.Nifti1Image(mask_hemisphere_left, affine), \"hemisphere_left.nii.gz\")\n",
    "nib.save(nib.Nifti1Image(mask_hemisphere_right, affine), \"hemisphere_right.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scm = f\"cleaned_scm_from_sm_{input_name_for_next_step}.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fsleyes to view the temporally smoothed motion corrected functional data\n",
    "\n",
    "# ---------- Common styling ----------\n",
    "input_layout = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "label_style = {'description_width': '410px'}\n",
    "\n",
    "# ---------- Widgets ----------\n",
    "right_slice = widgets.IntText(value=10, description=\"Right Hemisphere Slice:\", layout=input_layout, style=label_style)\n",
    "left_slice = widgets.IntText(value=10, description=\"Left Hemisphere Slice:\", layout=input_layout, style=label_style)\n",
    "\n",
    "for w in [right_slice, left_slice]:\n",
    "    w.style.description_width = \"180px\"\n",
    "\n",
    "# ---------- Container ----------\n",
    "row = widgets.HBox([right_slice, left_slice],\n",
    "    layout=widgets.Layout(width=\"40%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\"))\n",
    "\n",
    "row.layout.background_color = \"#1e1e1e\"\n",
    "row.layout.border = \"3px solid #444\"\n",
    "\n",
    "display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_slice_choosen = int(right_slice.value)\n",
    "left_slice_choosen  = int(left_slice.value)\n",
    "\n",
    "print_statement(f\"Your choosen slice for right hemisphere is: {right_slice_choosen}\", bcolors.OKGREEN)\n",
    "print_statement(f\"Your choosen slice for left hemisphere is: {left_slice_choosen}\", bcolors.OKGREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scm_path = \"clean_thresh_scm_from_sm_sm_mc_func.nii.gz\"\n",
    "\n",
    "res_left  = max_voxel_in_mask(scm_path, \"hemisphere_left.nii.gz\",  slice_pick=left_slice_choosen,  slice_pad=2)\n",
    "left_roi = save_roi_from_max(scm_path=\"clean_thresh_scm_from_sm_sm_mc_func.nii.gz\", hemisphere_mask_path=\"hemisphere_left.nii.gz\", res=res_left)\n",
    "roi_analysis(f\"{input_name_for_next_step}.nii.gz\", left_roi, n_vols, tr, base_start, base_end, sig_start, sig_end)\n",
    "print(\"LEFT:\", res_left)\n",
    "print(\"Saved:\", left_roi)\n",
    "\n",
    "res_right = max_voxel_in_mask(scm_path, \"hemisphere_right.nii.gz\", slice_pick=right_slice_choosen, slice_pad=2)\n",
    "right_roi = save_roi_from_max(scm_path=\"clean_thresh_scm_from_sm_sm_mc_func.nii.gz\", hemisphere_mask_path=\"hemisphere_right.nii.gz\", res=res_right)\n",
    "roi_analysis(f\"{input_name_for_next_step}.nii.gz\", right_roi, n_vols, tr, base_start, base_end, sig_start, sig_end)\n",
    "print(\"RIGHT:\", res_right)\n",
    "print(\"Saved:\", right_roi)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
