{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Honor Code:\n",
    "    @author: Naman Jain\n",
    "    @github: njainmpi\n",
    "    date: 06 jan, 2026\n",
    "    Description: \"analysing fmri data to generate signal change map.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Importing Libraries needed to run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nipype.interfaces import afni, fsl\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import re\n",
    "import getpass\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from nilearn import image, plotting\n",
    "import scipy.stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# All Functions to be used throughout the analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Apply temporal smoothing on raw functional data by applying moving mean.\n",
    "    Parameters:\n",
    "    in_file (str): path for input file type 4d nifti.\n",
    "    out_file (str): path  for output file type 4d nifti.\n",
    "    win_sec_duration (float):  window duration in volums.\n",
    "    tr (float): repetition time (in sec)\n",
    "\"\"\"    \n",
    "def smooth_movavg(in_file, out_file, win_sec_duration, tr):\n",
    "\n",
    "  win = max(1, int(round(win_sec_duration / tr)))\n",
    "  \n",
    "  # Apply moving average\n",
    "  def moving_average_1d(x, win):\n",
    "      k = np.ones(win, dtype=float) / win\n",
    "      xpad = np.pad(x, (win//2, win-1-win//2), mode='edge')  # reduce edge shrinkage\n",
    "      return np.convolve(xpad, k, mode='valid')\n",
    "\n",
    "  img = nib.load(in_file)\n",
    "  data = img.get_fdata()   # X,Y,Z,T\n",
    "  T = data.shape[-1]\n",
    "  flat = data.reshape(-1, T)\n",
    "  sm = np.vstack([moving_average_1d(ts, win) for ts in flat]).reshape(data.shape)\n",
    "\n",
    "  nib.Nifti1Image(sm, img.affine, img.header).to_filename(out_file)\n",
    "  print(f\"Wrote: {out_file}  (tr={tr}s, window={win_sec_duration}s => {win} vols)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Convert bruker raw format to readable nifti format\n",
    "    Parameters:\n",
    "    in_path: location of raw data\n",
    "    scan_number: run that you want to convert\n",
    "\"\"\" \n",
    "def bruker_to_nifti(in_path, scan_number):\n",
    "    \n",
    "    scan_dir = os.path.join(in_path, scan_number)\n",
    "    method_file = os.path.join(scan_dir, \"method\")\n",
    "\n",
    "    # ---------- 1) Run brkraw tonii ----------\n",
    "    cmd = [\"brkraw\", \"tonii\", f\"{in_path}/\", \"-s\", str(scan_number)]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    # ---------- 2) Detect echo count in \"method\" ----------\n",
    "    if \"PVM_NEchoImages\" in open(method_file).read():\n",
    "        # Extract number of echoes using awk logic in Python\n",
    "        with open(method_file) as f:\n",
    "            for line in f:\n",
    "                if \"PVM_NEchoImages=\" in line:\n",
    "                    # Extract numeric part exactly like Bash substring 20..21\n",
    "                    echo_str = line.split(\"=\")[1].strip()\n",
    "                    NoOfEchoImages = int(echo_str)\n",
    "                    break\n",
    "\n",
    "        # ---------- 3) If single echo ----------\n",
    "        if NoOfEchoImages == 1:\n",
    "            src_files = glob.glob(f\"*{scan_number}*\")\n",
    "            for src in src_files:\n",
    "                shutil.copy(src, \"G1_cp.nii.gz\")\n",
    "\n",
    "        # ---------- 4) Multi-echo: merge then copy ----------\n",
    "        else:\n",
    "            merged_file = f\"{scan_number}_combined_images\"\n",
    "            src_files = glob.glob(f\"*{scan_number}*\")\n",
    "            # fslmerge -t combined.nii.gz file1 file2 file3 ...\n",
    "            subprocess.run([\"fslmerge\", \"-t\", merged_file] + src_files, check=True)\n",
    "            shutil.copy(f\"{merged_file}.nii.gz\", \"G1_cp.nii.gz\")\n",
    "\n",
    "    else:\n",
    "        # ---------- 5) No echo metadata ----------\n",
    "        src_files = glob.glob(f\"*{scan_number}*\")\n",
    "        for src in src_files:\n",
    "            shutil.copy(src, \"G1_cp.nii.gz\")\n",
    "\n",
    "    print(f\"{bcolors.NOTIFICATION}Fixing orientation to LPI{bcolors.ENDC}\")\n",
    "\n",
    "    # ---------- 6) Fix orientation to LPI using 3dresample ----------\n",
    "    resample = afni.Resample()\n",
    "    resample.inputs.in_file = \"G1_cp.nii.gz\"\n",
    "    resample.inputs.out_file = \"G1_cp_resampled.nii.gz\"\n",
    "    resample.inputs.orientation = \"LPI\"\n",
    "    resample.run()\n",
    "\n",
    "    # ---------- 7) Save NIfTI header info ----------\n",
    "    with open(\"NIFTI_file_header_info.txt\", \"w\") as out:\n",
    "        subprocess.run([\"fslhd\", \"G1_cp_resampled.nii.gz\"], stdout=out, check=True)\n",
    "\n",
    "    print_statement(f\"[OK] Bruker → NIFTI workflow completed.\", bcolors.OKGREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_middle_volume(in_file, reference_vol, out_file, size):\n",
    "  extract_vol = fsl.ExtractROI()\n",
    "  extract_vol.inputs.in_file=in_file \n",
    "  extract_vol.inputs.t_min=reference_vol \n",
    "  extract_vol.inputs.t_size=size \n",
    "  extract_vol.inputs.roi_file=out_file\n",
    "  extract_vol.run()\n",
    "\n",
    "  print(\"[OK] Intended Volumes extracted.\")\n",
    "  return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_correction(reference_vol, input_vol, output_prefix):\n",
    "\n",
    "    # ---------- 1) 3dvolreg ----------\n",
    "    \n",
    "    volreg = afni.Volreg()  \n",
    "    volreg.inputs.in_file = input_vol\n",
    "    volreg.inputs.basefile = reference_vol\n",
    "    volreg.inputs.out_file = f\"{output_prefix}.nii.gz\"\n",
    "    volreg.inputs.oned_file = \"motion.1D\"\n",
    "    volreg.inputs.args = '-linear'\n",
    "    volreg.inputs.oned_matrix_save = \"mats\"\n",
    "    volreg.inputs.oned_matrix_save = \"rmsabs.1D\"\n",
    "    volreg.inputs.verbose = True\n",
    "    volreg.run()\n",
    "\n",
    "    print(\"[INFO] Running 3dvolreg…\")\n",
    "    return output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motion_parameters(input_file):\n",
    "    # ---------- 4) Plot motion parameters ----------\n",
    "    print(\"[INFO] Creating motion plots…\")\n",
    "\n",
    "    # Translation plots\n",
    "    data = np.loadtxt(input_file)\n",
    "\n",
    "    # If your file HAS a header, use:\n",
    "    # data = np.loadtxt(\"your_file.1D\", comments=\"#\")\n",
    "\n",
    "    # X-axis (row index / timepoints)\n",
    "    x = np.arange(data.shape[0])\n",
    "\n",
    "    # -------- Plot 1: first 3 columns --------\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(3):\n",
    "        plt.plot(x, data[:, i], label=f\"Column {i+1}\")\n",
    "\n",
    "    plt.title(\"Rotation\")\n",
    "    plt.xlabel(\"Volume Number\")\n",
    "    plt.ylabel(\"Rotation in degrees\")\n",
    "    plt.legend([\"Pitch (x)\", \"Roll (y)\", \"Yaw (z)\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"motion_rotations.svg\", dpi=1200)\n",
    "    # -------- Plot 2: next 3 columns --------\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(3, 6):\n",
    "        plt.plot(x, data[:, i], label=f\"Column {i+1}\")\n",
    "\n",
    "    plt.title(\"Translation\")\n",
    "    plt.xlabel(\"Volume Number\")\n",
    "    plt.ylabel(\"Translation in mm\")\n",
    "    plt.legend([\"Read (x)\", \"Phase (y)\", \"Slice (z)\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"motion_translations.svg\", dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_range(input_file, prefix, start_idx, end_idx):\n",
    "    \n",
    "    afni_cmd = [\"3dTstat\", \"-mean\", \"-prefix\", prefix, f\"{input_file}[{start_idx}..{end_idx}]\"]\n",
    "\n",
    "    print(\"[INFO] Running:\", \" \".join(afni_cmd))\n",
    "\n",
    "    subprocess.run(afni_cmd, check=True)\n",
    "    print_statement(\"[OK] Mean baseline image saved.\", bcolors.OKGREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_file(input_file, mask_file, output_file):\n",
    "  \n",
    "  math = fsl.maths.ApplyMask()\n",
    "  math.inputs.in_file = input_file\n",
    "  math.inputs.mask_file = mask_file\n",
    "  math.inputs.out_file = output_file\n",
    "\n",
    "  math.run()\n",
    "\n",
    "  print_statement(f\"[OK] Masked file saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tSNR(input_file, output_file, reference_vol, size):\n",
    "  \n",
    "  extract_middle_volume(input_file, reference_vol, \"extracted_ts.nii.gz\", size)\n",
    "\n",
    "  mean = fsl.maths.MeanImage()\n",
    "  mean.inputs.in_file = \"extracted_ts.nii.gz\"\n",
    "  mean.inputs.out_file = \"mean_image.nii.gz\"\n",
    "  mean.run()\n",
    "\n",
    "  std = fsl.maths.StdImage()\n",
    "  std.inputs.in_file = \"extracted_ts.nii.gz\"\n",
    "  std.inputs.out_file = \"std_image.nii.gz\"\n",
    "  std.run()\n",
    "\n",
    "  tSNR = fsl.maths.BinaryMaths()\n",
    "  tSNR.inputs.in_file = \"mean_image.nii.gz\"\n",
    "  tSNR.inputs.operand_file = \"std_image.nii.gz\"\n",
    "  tSNR.inputs.operation = \"div\"\n",
    "  tSNR.inputs.out_file = output_file\n",
    "  tSNR.run()\n",
    "\n",
    "  print_statement(f\"[OK] tSNR file saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_smoothing(input_file, output_file, fwhm):\n",
    "  \n",
    "  smooth = fsl.maths.IsotropicSmooth()\n",
    "  smooth.inputs.in_file = input_file\n",
    "  smooth.inputs.out_file = output_file\n",
    "  # smooth.inputs.fwhm = fwhm\n",
    "  smooth.inputs.sigma = fwhm / 2.3548  # Convert FWHM to sigma\n",
    "\n",
    "  smooth.run()\n",
    "\n",
    "  print_statement(f\"[OK] Spatially smoothed file saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_change_map(signal_file, baseline_file, output_file):\n",
    "   \n",
    "  tmp_sub = \"tmp_signal_minus_baseline.nii.gz\"\n",
    "  tmp_div = \"tmp_psc_raw.nii.gz\"\n",
    "\n",
    "  sub = fsl.BinaryMaths()\n",
    "  sub.inputs.in_file = signal_file\n",
    "  sub.inputs.operand_file = baseline_file\n",
    "  sub.inputs.operation = \"sub\"\n",
    "  sub.inputs.out_file = tmp_sub\n",
    "  sub.run()\n",
    "\n",
    "  div = fsl.BinaryMaths()\n",
    "  div.inputs.in_file = tmp_sub\n",
    "  div.inputs.operand_file = baseline_file\n",
    "  div.inputs.operation = \"div\"\n",
    "  div.inputs.out_file = tmp_div\n",
    "  div.run()\n",
    "\n",
    "  mul = fsl.BinaryMaths()\n",
    "  mul.inputs.in_file = tmp_div\n",
    "  mul.inputs.operation = \"mul\"\n",
    "  mul.inputs.operand_value = 100\n",
    "  mul.inputs.out_file = output_file\n",
    "  mul.run()\n",
    "\n",
    "  os.remove(tmp_sub)\n",
    "  os.remove(tmp_div)\n",
    "\n",
    "  print_statement(f\"[OK] Percent Signal Change Map saved → {output_file}\", bcolors.OKGREEN)\n",
    "  return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coregistration_afni(input_file1=None, input_file2=None, reference_file=None, output_file1=None, output_file2=None, estimate_affine=True, apply_affine=True, affine_mat=\"mean_func_struct_aligned.aff12.1D\"):\n",
    "\n",
    "  results = {}\n",
    "\n",
    "  # -------- STEP 1: Estimate affine --------\n",
    "  if estimate_affine:\n",
    "      if output_file1 is None:\n",
    "          raise ValueError(\"output_file1 must be provided when estimate_affine=True\")\n",
    "      if input_file1 is None:\n",
    "          raise ValueError(\"input_file1 must be provided when estimate_affine=True\")\n",
    "\n",
    "      coreg_wo_affine = afni.Allineate()\n",
    "      coreg_wo_affine.inputs.in_file = input_file1\n",
    "      coreg_wo_affine.inputs.reference = reference_file\n",
    "      coreg_wo_affine.inputs.out_matrix = affine_mat\n",
    "      coreg_wo_affine.inputs.cost = \"crU\"\n",
    "      coreg_wo_affine.inputs.two_pass = True\n",
    "      coreg_wo_affine.inputs.verbose = True\n",
    "      coreg_wo_affine.inputs.out_file = output_file1\n",
    "      coreg_wo_affine.inputs.out_param_file = \"params.1D\"\n",
    "      coreg_wo_affine.run()\n",
    "\n",
    "      print(f\"[OK] Affine estimated and saved → {affine_mat}\")\n",
    "      print(f\"[OK] Coregistered image (step 1) → {output_file1}\")\n",
    "\n",
    "      results[\"step1\"] = output_file1\n",
    "\n",
    "  # -------- STEP 2: Apply affine --------\n",
    "  if apply_affine:\n",
    "      if output_file2 is None:\n",
    "          raise ValueError(\"output_file2 must be provided when apply_affine=True\")\n",
    "      if input_file2 is None:\n",
    "          raise ValueError(\"input_file2 must be provided when apply_affine=True\")\n",
    "\n",
    "\n",
    "      coreg_with_affine = afni.Allineate()\n",
    "      coreg_with_affine.inputs.in_file = input_file2\n",
    "      coreg_with_affine.inputs.reference = reference_file\n",
    "      coreg_with_affine.inputs.in_matrix = affine_mat\n",
    "      coreg_with_affine.inputs.master = reference_file\n",
    "      coreg_with_affine.inputs.verbose = True\n",
    "      coreg_with_affine.inputs.final_interpolation = \"linear\"\n",
    "      coreg_with_affine.inputs.out_file = output_file2\n",
    "      coreg_with_affine.run()\n",
    "\n",
    "      print_statement(f\"[OK] Affine applied → {output_file2}\", bcolors.OKGREEN)\n",
    "      results[\"step2\"] = output_file2\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_course_extraction(roi_file, func_file, output_file):\n",
    "   \n",
    "    ts = fsl.ImageMeants()\n",
    "    ts.inputs.in_file = func_file\n",
    "    ts.inputs.mask = roi_file\n",
    "    ts.inputs.out_file = output_file\n",
    "\n",
    "    ts.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_param_extract(scan_dir, export_env=True):\n",
    "\n",
    "    scan_dir = Path(scan_dir)\n",
    "    acqp_file = scan_dir / \"acqp\"\n",
    "    method_file = scan_dir / \"method\"\n",
    "    \n",
    "\n",
    "    if not acqp_file.exists() or not method_file.exists():\n",
    "        raise FileNotFoundError(\"acqp or method file not found\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Read files\n",
    "    # -----------------------------\n",
    "    acqp_text = acqp_file.read_text()\n",
    "    method_text = method_file.read_text()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Sequence name (ACQ_protocol_name)\n",
    "    # -----------------------------\n",
    "    seq_match = re.search(\n",
    "        r\"ACQ_protocol_name=\\(\\s*64\\s*\\)\\s*\\n\\s*<([^>]+)>\",\n",
    "        acqp_text\n",
    "    )\n",
    "    SequenceName = seq_match.group(1) if seq_match else None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract numeric parameters\n",
    "    # -----------------------------\n",
    "    def get_value(pattern, text, cast=int):\n",
    "        m = re.search(pattern, text)\n",
    "        return cast(m.group(1)) if m else None\n",
    "\n",
    "    NoOfRepetitions = get_value(r\"##\\$PVM_NRepetitions=\\s*(\\d+)\", method_text)\n",
    "    TotalScanTime = get_value(r\"##\\$PVM_ScanTime=\\s*(\\d+)\", method_text)\n",
    "\n",
    "    Baseline_TRs = get_value(r\"PreBaselineNum=\\s*(\\d+)\", method_text)\n",
    "    StimOn_TRs = get_value(r\"StimNum=\\s*(\\d+)\", method_text)\n",
    "    StimOff_TRs = get_value(r\"InterStimNum=\\s*(\\d+)\", method_text)\n",
    "    NoOfEpochs = get_value(r\"NEpochs=\\s*(\\d+)\", method_text)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Derived values\n",
    "    # -----------------------------\n",
    "    VolTR_msec = None\n",
    "    VolTR = None\n",
    "    MiddleVolume = None\n",
    "\n",
    "    if NoOfRepetitions and TotalScanTime:\n",
    "        VolTR_msec = TotalScanTime / NoOfRepetitions\n",
    "        VolTR = VolTR_msec / 1000\n",
    "        MiddleVolume = NoOfRepetitions / 2\n",
    "\n",
    "    # -----------------------------\n",
    "    # Pack results\n",
    "    # -----------------------------\n",
    "    params = {\n",
    "        \"SequenceName\": SequenceName,\n",
    "        \"NoOfRepetitions\": NoOfRepetitions,\n",
    "        \"TotalScanTime\": TotalScanTime,\n",
    "        \"VolTR_msec\": VolTR_msec,\n",
    "        \"VolTR\": VolTR,\n",
    "        \"Baseline_TRs\": Baseline_TRs,\n",
    "        \"StimOn_TRs\": StimOn_TRs,\n",
    "        \"StimOff_TRs\": StimOff_TRs,\n",
    "        \"NoOfEpochs\": NoOfEpochs,\n",
    "        \"MiddleVolume\": MiddleVolume,\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Export to environment (optional)\n",
    "    # -----------------------------\n",
    "    if export_env:\n",
    "        for k, v in params.items():\n",
    "            if v is not None:\n",
    "                os.environ[k] = str(v)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_id(scan_dir):\n",
    "    subject_file = Path(scan_dir) / \"subject\"\n",
    "\n",
    "    if not subject_file.exists():\n",
    "        raise FileNotFoundError(f\"'subject' file not found in {scan_dir}\")\n",
    "\n",
    "    with subject_file.open(\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"##$SUBJECT_id\"):\n",
    "            # The value is expected on the next line\n",
    "            value_line = lines[i + 1].strip()\n",
    "            return value_line.strip(\"<>\")\n",
    "\n",
    "    raise ValueError(\"##$SUBJECT_id not found in subject file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_header(message, color):\n",
    "    line = \"*\" * 134   # same width everywhere\n",
    "    width = len(line)\n",
    "\n",
    "    print()\n",
    "    print(f\"{color}{line}{bcolors.ENDC}\")\n",
    "    print(f\"{color}{message.center(width)}{bcolors.ENDC}\")\n",
    "    print(f\"{color}{line}{bcolors.ENDC}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statement(message, color):\n",
    "    print(f\"{color}{message}{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    NOTIFICATION = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_images(input_image, cmap=\"gray\"):\n",
    "    img = nib.load(input_image)\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Handle 4D vs 3D safely\n",
    "    if data.ndim == 4:\n",
    "        data = data[..., 0]   # take first volume\n",
    "    elif data.ndim != 3:\n",
    "        raise ValueError(f\"Unsupported data shape: {data.shape}\")\n",
    "\n",
    "    ny = data.shape[1]\n",
    "    cols = 8\n",
    "    rows = int(np.ceil(ny / cols))\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = np.atleast_1d(axes).flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < ny:\n",
    "            ax.imshow(data[:, i, :].T, cmap=cmap, origin=\"lower\")\n",
    "            ax.set_title(f\"y={i}\", fontsize=14)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_nifti_files(directory, ref_shape):\n",
    "    matches = []\n",
    "\n",
    "    ref_xyz = tuple(ref_shape[:3])  # (64,16,64)\n",
    "    print(f\"Reference spatial shape: {ref_xyz}\")\n",
    "\n",
    "    for f in sorted(os.listdir(directory)):\n",
    "        if f.endswith((\".nii\", \".nii.gz\")):\n",
    "            try:\n",
    "                img = nib.load(os.path.join(directory, f))\n",
    "                img_xyz = tuple(img.shape[:3])\n",
    "\n",
    "                if img_xyz == ref_xyz:\n",
    "                    matches.append(f)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_analysis(func_in_file, roi_file, n_vols, tr, base_start, base_end, sig_start, sig_end):\n",
    "    print_statement(f\"Extracting time course for ROI: {roi_file}\", bcolors.NOTIFICATION)\n",
    "    output_file = f\"time_course_{roi_file.replace('.nii.gz', '.txt')}\"\n",
    "    time_course_extraction(roi_file, func_in_file, output_file)\n",
    "    print_statement(f\"[OK] Time course saved → {output_file}\", bcolors.OKGREEN)\n",
    "\n",
    "    #Creating Percent Signal Change graphs for each ROI\n",
    "    id_arr = list(range(0, n_vols, tr))\n",
    "    time_series = np.loadtxt(output_file)\n",
    "    # baseline = np.mean(time_series[base_start:base_end])\n",
    "    baseline = np.mean(time_series[base_start:base_end])\n",
    "    psc = ((time_series - baseline) / baseline) * 100\n",
    "    mean_signal = np.mean(psc[sig_start:sig_end])\n",
    "    print_statement(f\"[OK] Percent Signal Change calculated for ROI: {roi_file}\", bcolors.OKGREEN)\n",
    "    print(\"Time Series is:\", psc)\n",
    "    np.savetxt(f\"PSC_time_series_{roi_file.replace('.nii.gz', '.txt')}\", psc)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(id_arr, psc, label='Percent Signal Change')\n",
    "    plt.axvspan(base_start, base_end, color='green', alpha=0.3, label='Baseline Period')\n",
    "    plt.axvspan(sig_start, sig_end, color='blue', alpha=0.3, label='Signal Period')\n",
    "    plt.title(f'Percent Signal Change Time Series for {roi_file}')\n",
    "    plt.xlabel('Time Points (Volumes)')\n",
    "    plt.ylabel('MRI Signal Change (%)')\n",
    "    plt.set_ylim = (-2, 10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    graph_file = f\"PSC_Time_Series_{roi_file.replace('.nii.gz', '.svg')}\"\n",
    "    plt.savefig(graph_file, dpi=1200)\n",
    "    print_statement(f\"[OK] Percent Signal Change graph saved → {graph_file}\", bcolors.OKGREEN)   \n",
    "\n",
    "    return mean_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Based on the root location, selecting the folder where raw data is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing the raw data that needs to be analysed\n",
    "root_location = \"/Volumes/Extreme_Pro/fMRI\"\n",
    "selected_folder = FileChooser(root_location, layout=widgets.Layout(width='1080px'))\n",
    "selected_folder.show_only_dirs = True\n",
    "display(selected_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confirming the selection of raw data \n",
    "\n",
    "raw_data_path = selected_folder.selected_path\n",
    "print(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Common styling ----------\n",
    "input_layout = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "label_style = {'description_width': '410px'}\n",
    "\n",
    "# ---------- Widgets ----------\n",
    "func_scan_number_entered = widgets.IntText(value=10, description=\"Functional Scan:\", layout=input_layout, style=label_style)\n",
    "struct_scan_number_entered = widgets.IntText(value=10, description=\"Structural Scan:\", layout=input_layout, style=label_style)\n",
    "win_entered = widgets.IntText(value=100, description=\"Window Duration (in vols):\", layout=input_layout, style=label_style)\n",
    "temp_smoothing_window =  widgets.IntText(value=60, description=\"Temporal Smoothing (in vols):\", layout=input_layout, style=label_style)\n",
    "\n",
    "for w in [func_scan_number_entered, struct_scan_number_entered, win_entered, temp_smoothing_window]:\n",
    "    w.style.description_width = \"220px\"\n",
    "\n",
    "# ---------- Container ----------\n",
    "row = widgets.HBox([func_scan_number_entered, struct_scan_number_entered, win_entered, temp_smoothing_window],\n",
    "    layout=widgets.Layout(width=\"100%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\"))\n",
    "\n",
    "row.layout.background_color = \"#1e1e1e\"\n",
    "row.layout.border = \"3px solid #444\"\n",
    "\n",
    "display(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Selecting the Structural and functional run that needs to be analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(raw_data_path)\n",
    "subject_id = extract_subject_id(in_path)\n",
    "\n",
    "# Replace RawData with AnalysedData at folder level\n",
    "parts = list(in_path.parts)\n",
    "parts[parts.index(\"RawData\")] = \"AnalysedData\"\n",
    "\n",
    "analysed_base = Path(*parts).parent\n",
    "analysed_path = analysed_base / subject_id\n",
    "\n",
    "func_scan_number = str(func_scan_number_entered.value)\n",
    "struct_scan_number = str(struct_scan_number_entered.value)\n",
    "win = str(win_entered.value)\n",
    "\n",
    "print_statement(f\"Subject under analysis is {subject_id} for Functional Scan Number {func_scan_number} and Structural Scan Number {struct_scan_number}\", bcolors.NOTIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Converting Bruker data into NIFTI Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"Converting Bruker to NIFTI: Both Structural and Functional Data\", bcolors.HEADER)\n",
    "\n",
    "params_struct = func_param_extract(Path(in_path) / struct_scan_number,export_env=True)\n",
    "sequence_name_struct = params_struct[\"SequenceName\"]\n",
    "analysed_struct_dir = Path(analysed_path) / f\"{struct_scan_number}{sequence_name_struct}\"\n",
    "print_statement(f\"Analysed Data Path: {analysed_struct_dir}\", bcolors.NOTIFICATION)\n",
    "analysed_struct_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysed_struct_dir)\n",
    "\n",
    "# --- Check for existing NIfTI ---\n",
    "nifti_file = analysed_struct_dir / \"G1_cp_resampled.nii.gz\"\n",
    "\n",
    "if nifti_file.exists():\n",
    "    print_statement(\"NIfTI file already exists. Skipping conversion.\", bcolors.OKGREEN)\n",
    "else:\n",
    "    bruker_to_nifti(in_path, struct_scan_number)\n",
    "\n",
    "\n",
    "# --- Extract functional scan parameters ---\n",
    "params_func = func_param_extract(Path(in_path) / func_scan_number,export_env=True)\n",
    "sequence_name_func = params_func[\"SequenceName\"]\n",
    "analysed_func_dir = Path(analysed_path) / f\"{func_scan_number}{sequence_name_func}\"\n",
    "print_statement(f\"Analysed Data Path: {analysed_func_dir}\", bcolors.NOTIFICATION)\n",
    "analysed_func_dir.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(analysed_func_dir)\n",
    "\n",
    "# --- Check for existing NIfTI ---\n",
    "nifti_file = analysed_func_dir / \"G1_cp_resampled.nii.gz\"\n",
    "\n",
    "if nifti_file.exists():\n",
    "    print_statement(\"NIfTI file already exists. Skipping conversion.\", bcolors.OKGREEN)\n",
    "else:\n",
    "    bruker_to_nifti(in_path, func_scan_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Applying Motion Correction on raw functional data and plotting motion parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Motion Correction on raw functional data and plotting motion parameters\n",
    "\n",
    "print_header(\"Applying Motion Correction on raw functional data and plotting motion parameters\", bcolors.HEADER)\n",
    "\n",
    "path_raw_func = os.path.join(in_path, func_scan_number)\n",
    "# params = func_param_extract(path_raw_func, export_env=True)\n",
    "# SequenceName = params[\"SequenceName\"]\n",
    "tr = int(params_func[\"VolTR\"])\n",
    "n_vols = params_func[\"NoOfRepetitions\"]\n",
    "middle_vol = str(int(n_vols / 2))\n",
    "\n",
    "extract_middle_volume(\"G1_cp_resampled.nii.gz\", int(middle_vol), \"middle_vol.nii.gz\", 1)\n",
    "\n",
    "if os.path.exists(\"mc_func.nii.gz\"):\n",
    "    print(f\"{bcolors.OKGREEN}Motion Corrected functional data exists. Skipping motion correction.{bcolors.ENDC}\")\n",
    "else:\n",
    "    motion_correction(\"middle_vol.nii.gz\", input_vol=\"G1_cp_resampled.nii.gz\", output_prefix=\"mc_func\")\n",
    "\n",
    "\n",
    "#Display of the motion corrected image and motion corrected graphs\n",
    "view_images(\"mc_func.nii.gz\", cmap=\"gray\")\n",
    "plot_motion_parameters(\"motion.1D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Creating a mask to be applied on functional data using the mean baseline image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mask to be applied on functional data using the mean baseline image\n",
    "\n",
    "mask_file = \"mask_mean_mc_func.nii.gz\"\n",
    "mask_file_cannulas = \"mask_mean_mc_func_cannulas.nii.gz\"\n",
    "\n",
    "if os.path.exists(mask_file):\n",
    "    print(f\"{bcolors.OKGREEN}Mask Image ({mask_file}) exists.{bcolors.ENDC}\")\n",
    "else:\n",
    "    print(f\"{bcolors.FAIL}Mask Image does not exist. Please create the mask and save it as mask_mean_mc_func.nii.gz{bcolors.ENDC}\")\n",
    "    subprocess.run([\"fsleyes\", \"middle_vol.nii.gz\"])\n",
    "\n",
    "if os.path.exists(mask_file_cannulas):\n",
    "    print(f\"{bcolors.OKGREEN}Mask Image including cannulas ({mask_file_cannulas}) exist.{bcolors.ENDC}\")\n",
    "else:\n",
    "    print(f\"{bcolors.FAIL}Mask Image does not exist. Please create the mask that also includes cannulas and save it as mask_mean_mc_func_cannulas.nii.gz.{bcolors.ENDC}\")\n",
    "    shutil.copyfile(\"mask_mean_mc_func.nii.gz\", \"mask_mean_mc_func_cannulas.nii.gz\")\n",
    "    subprocess.run([\"fsleyes\", \"mean_image.nii.gz\" , \"mask_mean_mc_func_cannulas.nii.gz\"])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Setting up analysis directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"Setting up Analysis Directory\", bcolors.HEADER)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "user = getpass.getuser()\n",
    "folder_created = f\"{timestamp}_{user}\"\n",
    "\n",
    "analysis_dir = Path(analysed_path) / f\"{func_scan_number}{sequence_name_func}\" / folder_created\n",
    "analysis_dir.mkdir(parents=True, exist_ok=False)  # fail loudly if it already exists\n",
    "\n",
    "src_dir = Path.cwd()\n",
    "files_to_copy = [\"mc_func.nii.gz\", mask_file, mask_file_cannulas]\n",
    "\n",
    "for name in files_to_copy:\n",
    "    src = src_dir / name\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"Missing required file: {src}\")\n",
    "    shutil.copy2(src, analysis_dir / name)\n",
    "\n",
    "\n",
    "os.chdir(analysis_dir)\n",
    "print(f\"Current Working Directory is: {analysis_dir.resolve()}\")\n",
    "cwd = str(analysis_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Applying temporal smoothing to the motion corrected functional data to see the temporal signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying temporal smoothing to the motion corrected functional data to see the temporal signatures\n",
    "print_header(\"Applying temporal smoothing to the motion corrected functional data to see the temporal signatures\", bcolors.HEADER)\n",
    "smooth_movavg(\"mc_func.nii.gz\", \"temporal_smoothed_mc_func.nii.gz\", temp_smoothing_window.value, tr)\n",
    "\n",
    "# Opening fsleyes to view the temporally smoothed motion corrected functional data\n",
    "print_statement(\"Choose your baseline and signal volumes from the temporally smoothed motion corrected functional data.\", bcolors.NOTIFICATION)\n",
    "subprocess.run([\"fsleyes\", \"temporal_smoothed_mc_func.nii.gz\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# Choosing signal and baseline volume indices from the temporally smoothed motion corrected functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Common styling ----------\n",
    "input_layout = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "label_style = {'description_width': '410px'}\n",
    "\n",
    "# ---------- Widgets ----------\n",
    "base_start_idx = widgets.IntText(value=10, description=\"Baseline Start Index:\", layout=input_layout, style=label_style)\n",
    "sig_start_idx = widgets.IntText(value=10, description=\"Signal Start Index:\", layout=input_layout, style=label_style)\n",
    "\n",
    "for w in [base_start_idx, sig_start_idx]:\n",
    "    w.style.description_width = \"180px\"\n",
    "\n",
    "# ---------- Container ----------\n",
    "row = widgets.HBox([base_start_idx, sig_start_idx],\n",
    "    layout=widgets.Layout(width=\"40%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\"))\n",
    "\n",
    "row.layout.background_color = \"#1e1e1e\"\n",
    "row.layout.border = \"3px solid #444\"\n",
    "\n",
    "display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_start = int(base_start_idx.value)\n",
    "sig_start  = int(sig_start_idx.value)\n",
    "base_end   = base_start + int(win_entered.value)\n",
    "sig_end   = sig_start + int(win_entered.value)\n",
    "\n",
    "print_statement(f\"Your baseline window selected is: {base_start}_to_{base_end}\", bcolors.OKGREEN)\n",
    "print_statement(f\"Your signal window selected is: {sig_start}_to_{sig_end}\", bcolors.OKGREEN)\n",
    "\n",
    "compute_mean_range(input_file=\"temporal_smoothed_mc_func.nii.gz\", prefix=f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", start_idx=base_start, end_idx=base_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking temporally smoothed motion corrected functional data using the created mask\n",
    "print_header(\"Masking temporally smoothed motion corrected functional data using the created mask\", bcolors.HEADER)\n",
    "masking_file(input_file=\"temporal_smoothed_mc_func.nii.gz\", mask_file=\"mask_mean_mc_func.nii.gz\", output_file=\"cleaned_mc_func.nii.gz\") #creating cleaned motion corrected functional data from temporal smoothed data for further processing\n",
    "masking_file(input_file=\"mc_func.nii.gz\", mask_file=\"mask_mean_mc_func.nii.gz\", output_file=\"raw_cleaned_mc_func.nii.gz\") #creating cleaned motion corrected functional data from raw data for different processing\n",
    "masking_file(input_file=\"temporal_smoothed_mc_func.nii.gz\", mask_file=\"mask_mean_mc_func_cannulas.nii.gz\", output_file=\"cleaned_mc_func_cannulas.nii.gz\") #creating cleaned motion corrected functional data from temporal smoothed data for further processing\n",
    "masking_file(input_file= f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", mask_file=\"mask_mean_mc_func_cannulas.nii.gz\", output_file=\"cleaned_mean_mc_func_cannulas.nii.gz\")\n",
    "os.remove(f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Estimating tSNR using the cleaned motion corrected functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating tSNR using the cleaned motion corrected functional data\n",
    "print_header(\"Estimating tSNR using the cleaned motion corrected functional data\", bcolors.HEADER)\n",
    "tSNR(input_file=\"cleaned_mc_func.nii.gz\", reference_vol=100, output_file=\"tSNR_mc_func.nii.gz\", size=400)\n",
    "view_images(\"tSNR_mc_func.nii.gz\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Applying isotropic spatial smoothing on cleaned motion corrected functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying isotropic spatial smoothing on cleaned motion corrected functional data\n",
    "fwhm_kernel = float(0.4)\n",
    "print_header(\"Applying isotropic spatial smoothing on cleaned_mc_func.nii.gz\", bcolors.HEADER)\n",
    "spatial_smoothing('cleaned_mc_func.nii.gz', 'smoothed_cleaned_mc_func.nii.gz', fwhm_kernel)\n",
    "view_images(\"smoothed_cleaned_mc_func.nii.gz\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Generating Signal Change Map and Signal Change Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Signal Change Map\n",
    "\n",
    "print_header(\"Generating Signal Change Map and Signal Change Time Series\", bcolors.HEADER)\n",
    "\n",
    "compute_mean_range(input_file=\"smoothed_cleaned_mc_func.nii.gz\", prefix=f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", start_idx=base_start, end_idx=base_end)\n",
    "compute_mean_range(input_file=\"smoothed_cleaned_mc_func.nii.gz\", prefix=f\"mean_signal_image_{sig_start}_to_{sig_end}.nii.gz\", start_idx=sig_start, end_idx=sig_end)\n",
    "\n",
    "signal_change_map(f\"mean_signal_image_{sig_start}_to_{sig_end}.nii.gz\", f\"mean_baseline_image_{base_start}_to_{base_end}.nii.gz\", \"tmp_signal_change_map.nii.gz\")\n",
    "masking_file(input_file=\"tmp_signal_change_map.nii.gz\", mask_file=\"mask_mean_mc_func.nii.gz\", output_file=\"cleaned_SCM_func.nii.gz\") #cleaning the signal change map\n",
    "os.remove(\"tmp_signal_change_map.nii.gz\")\n",
    "view_images(\"cleaned_SCM_func.nii.gz\", cmap=\"inferno\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating time series of signal change\n",
    "\n",
    "print_header(\"Creating time series of signal change\", bcolors.HEADER)\n",
    "\n",
    "compute_mean_range(input_file=\"smoothed_cleaned_mc_func.nii.gz\", prefix=f\"mean_sm_baseline_image_{base_start}_to_{base_end}.nii.gz\", start_idx=base_start, end_idx=base_end)\n",
    "signal_change_map(\"smoothed_cleaned_mc_func.nii.gz\", f\"mean_sm_baseline_image_{base_start}_to_{base_end}.nii.gz\", \"tmp_signal_change_time_series.nii.gz\")\n",
    "masking_file(\"tmp_signal_change_time_series.nii.gz\", \"mask_mean_mc_func.nii.gz\", \"norm_cleaned_mc_func.nii.gz\")\n",
    "os.remove(\"tmp_signal_change_time_series.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# Cleaning the structural image by masking it with a manually created mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the structural image by masking it with a manually created mask\n",
    "\n",
    "print_header(\"Cleaning the structural image by manually creating mask\", bcolors.HEADER)\n",
    "struct_coreg_dir = os.path.join(analysed_path, str(struct_scan_number) + sequence_name_struct)\n",
    "\n",
    "structural_file_for_coregistration = os.path.join(struct_coreg_dir, \"cleaned_anatomy.nii.gz\")\n",
    "if os.path.exists(os.path.join(struct_coreg_dir, \"cleaned_anatomy.nii.gz\")):\n",
    "    print_statement(\"Structural Image for Coregistration exists.\", bcolors.OKGREEN)\n",
    "else:\n",
    "    print_statement(\"Please create a mask for the structural image and save it as mask_anatomy.nii.gz\", bcolors.NOTIFICATION)\n",
    "    subprocess.run([\"fsleyes\", os.path.join(struct_coreg_dir, \"G1_cp_resampled.nii.gz\")])\n",
    "    masking_file(os.path.join(struct_coreg_dir, \"G1_cp_resampled.nii.gz\"), os.path.join(struct_coreg_dir, \"mask_anatomy.nii.gz\"), structural_file_for_coregistration)\n",
    "\n",
    "view_images(os.path.join(struct_coreg_dir, \"cleaned_anatomy.nii.gz\"), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# Coregistering functional time series and functional signal change map to structural image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coregistering functional time series and functional signal change map to structural image\n",
    "print_header(\"Coregistering functional time series and functional signal change map to structural image\", bcolors.HEADER)\n",
    "affine_matrix_file = (\"mean_func_struct_aligned.aff12.1D\")\n",
    "if os.path.exists(affine_matrix_file):\n",
    "   print_statement(\"Affine Matrix to coregister Signal Change Map exists.\", bcolors.OKGREEN)\n",
    "else:\n",
    "   print_statement(\"Estimating Affine Matrix to coregister Signal Change Map.\", bcolors.NOTIFICATION)\n",
    "   coregistration_afni(input_file1=\"cleaned_mean_mc_func_cannulas.nii.gz\", input_file2=\"cleaned_SCM_func.nii.gz\", reference_file= structural_file_for_coregistration, output_file1=\"mean_func_struct_aligned.nii.gz\", output_file2=\"signal_change_map_coregistered_structural_space.nii.gz\", estimate_affine=True, apply_affine=True, affine_mat=\"mean_func_struct_aligned.aff12.1D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Coregistering functional time series and generating signal change map from coregistered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coregistering functional time series and generating signal change map from coregistered data\n",
    "\n",
    "print_header(\"Coregistering functional time series and generating signal change map from coregistered data\", bcolors.HEADER)\n",
    "coregistration_afni(input_file1=None, input_file2=\"cleaned_mc_func_cannulas.nii.gz\", reference_file= structural_file_for_coregistration, output_file1=None, output_file2=\"fMRI_coregistered_to_struct.nii.gz\", estimate_affine=False, apply_affine=True, affine_mat=\"mean_func_struct_aligned.aff12.1D\")\n",
    "\n",
    "mean = fsl.maths.MeanImage()\n",
    "mean.inputs.in_file = \"fMRI_coregistered_to_struct.nii.gz\"\n",
    "mean.inputs.out_file = \"mean_fMRI_coregistered_to_struct.nii.gz\"\n",
    "mean.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# Spatial smoothing of the coregistered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatially smoothing of the coregistered image\n",
    "fwhm_kernel_coregsitered = float(0.1)\n",
    "spatial_smoothing(\"fMRI_coregistered_to_struct.nii.gz\", \"sm_fMRI_coregistered_to_struct.nii.gz\", fwhm_kernel_coregsitered)\n",
    "view_images(\"sm_fMRI_coregistered_to_struct.nii.gz\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "# Generating Signal Change Maps from the coregistered functional image to structural image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(os.path.join(analysed_path, str(func_scan_number) + sequence_name_func, \"mask_mean_fMRI_coregistered_to_struct.nii.gz\")):\n",
    "    print(\"Mask file mask_mean_fMRI_coregistered_to_struct.nii.gz exists.\")\n",
    "else:\n",
    "    print(\"Please create a mask and save it as mask_mean_fMRI_coregistered_to_struct.nii.gz\")\n",
    "    subprocess.run([\"fsleyes\", \"mean_fMRI_coregistered_to_struct.nii.gz\"])\n",
    "    shutil.copyfile(os.path.join(analysed_path, str(func_scan_number) + sequence_name_func, \"mask_mean_fMRI_coregistered_to_struct.nii.gz\"), \"mask_mean_fMRI_coregistered_to_struct.nii.gz\")\n",
    "\n",
    "masking_file(\"sm_fMRI_coregistered_to_struct.nii.gz\", os.path.join(analysed_path, str(func_scan_number) + sequence_name_func, \"mask_mean_fMRI_coregistered_to_struct.nii.gz\"), \"sm_fMRI_for_scm.nii.gz\")\n",
    "\n",
    "compute_mean_range(input_file=\"sm_fMRI_for_scm.nii.gz\", prefix=f\"baseline_sm_fMRI_for_scm_{base_start}_to_{base_end}.nii.gz\", start_idx=base_start, end_idx=base_end)\n",
    "compute_mean_range(input_file=\"sm_fMRI_for_scm.nii.gz\", prefix=f\"signal_sm_fMRI_for_scm_{sig_start}_to_{sig_end}.nii.gz\", start_idx=sig_start, end_idx=sig_end)\n",
    "\n",
    "signal_change_map(f\"signal_sm_fMRI_for_scm_{sig_start}_to_{sig_end}.nii.gz\", f\"baseline_sm_fMRI_for_scm_{base_start}_to_{base_end}.nii.gz\", f\"sm_coreg_func_Static_Map_{base_start}_to_{base_end}_and_{sig_start}_to_{sig_end}.nii.gz\")\n",
    "masking_file(f\"sm_coreg_func_Static_Map_{base_start}_to_{base_end}_and_{sig_start}_to_{sig_end}.nii.gz\", os.path.join(analysed_path, str(func_scan_number) + sequence_name_func, \"mask_mean_fMRI_coregistered_to_struct.nii.gz\"), \"cleaned_sm_scm_from_coregistered_ts.nii.gz\")\n",
    "\n",
    "view_images(\"cleaned_sm_scm_from_coregistered_ts.nii.gz\", cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "# Marking ROIs and saving time courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marking ROIs and saving time courses\n",
    "\n",
    "print_header(\"Marking ROIs and saving time courses\", bcolors.HEADER)\n",
    "\n",
    "print_statement(\"Please create ROIs on the functional time series and save them in the following particular format:\", bcolors.NOTIFICATION) \n",
    "print_statement(\"roi_{what protein/aav is there}_{is it direct injection or aav}_{analyte injeted}_{hemisphere side}.nii.gz\", bcolors.NOTIFICATION)\n",
    "print_statement(\"For Example: if GCaMP6f is directly injected in the left hemisphere and dopamine is injected in the right hemisphere following a viral injection, then the following ROIs should be created:\", bcolors.NOTIFICATION) \n",
    "print_statement(\"roi_GCaMP6f_direct_left.nii.gz or roi_dopamine_aav_right.nii.gz\", bcolors.FAIL)  \n",
    "\n",
    "subprocess.run([\"fsleyes\", \"mean_fMRI_coregistered_to_struct.nii.gz\"])\n",
    "\n",
    "files_list_roi = os.listdir(cwd)\n",
    "\n",
    "for file in files_list_roi:\n",
    "    if file.startswith(\"roi_\") and file.endswith(\"left.nii.gz\"):\n",
    "        roi_left = file\n",
    "    if file.startswith(\"roi_\") and file.endswith(\"right.nii.gz\"):\n",
    "        roi_right = file\n",
    "\n",
    "mean_signal_left = roi_analysis(\"fMRI_coregistered_to_struct.nii.gz\", roi_left, n_vols, tr, base_start, base_end, sig_start, sig_end)\n",
    "mean_signal_right = roi_analysis(\"fMRI_coregistered_to_struct.nii.gz\", roi_right, n_vols, tr, base_start, base_end, sig_start, sig_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "# Voxel-wise Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the dropdown select the file you want to test the correlation with\n",
    "fc = FileChooser(cwd, layout=widgets.Layout(width='1080px'))\n",
    "fc.show_only_dirs = False\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the selected file above using nibabel and then select for mask file and seed file\n",
    "func_file_for_correlation = fc.selected_filename\n",
    "print(func_file_for_correlation)\n",
    "img_func = nib.load(func_file_for_correlation)\n",
    "img_func.shape\n",
    "\n",
    "matches = matching_nifti_files(cwd, img_func.shape)\n",
    "dropdown_mask = widgets.Dropdown(options=matches, description='Mask file:', layout=widgets.Layout(width='40%'))\n",
    "display(dropdown_mask)\n",
    "\n",
    "dropdown_seed = widgets.Dropdown(options=matches, description='Seed file:', layout=widgets.Layout(width='40%'))\n",
    "display(dropdown_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data and extract voxel wise time series and save it\n",
    "mask_file_for_correlation = os.path.join(cwd, dropdown_mask.value)\n",
    "seed_file_for_correlation = os.path.join(cwd, dropdown_seed.value)\n",
    "\n",
    "\n",
    "var_func = nib.load(func_file_for_correlation).get_fdata()\n",
    "var_seed = nib.load(seed_file_for_correlation).get_fdata().astype(bool)\n",
    "var_mask = nib.load(mask_file_for_correlation).get_fdata().astype(bool)\n",
    "\n",
    "ts_seed = var_func[var_seed, :].T   # (time, voxels)\n",
    "print(\"Seed TS:\", ts_seed.shape)\n",
    "\n",
    "ts_mask = var_func[var_mask, :].T   # (time, voxels)\n",
    "print(\"Mask TS:\", ts_mask.shape)\n",
    "\n",
    "np.savetxt(\"roi_voxel_seed_timeseries.txt\", ts_seed, fmt=\"%.6f\", delimiter=\"\\t\")\n",
    "np.savetxt(\"roi_voxel_mask_timeseries.txt\", ts_mask, fmt=\"%.6f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Parameters for selecting start and end index for correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layout = widgets.Layout(width=\"280px\", flex=\"0 0 auto\")\n",
    "label_style = {'description_width': '410px'}\n",
    "\n",
    "# ---------- Widgets ----------\n",
    "start_idx_correlation = widgets.IntText(value=1300, description=\"Start Index for Correlation: \", layout=input_layout, style=label_style)\n",
    "stop_idx_correlation = widgets.IntText(value=2300, description=\"End Index for Correlation: \", layout=input_layout, style=label_style)\n",
    "\n",
    "for w in [start_idx_correlation, stop_idx_correlation]:\n",
    "    w.style.description_width = \"180px\"\n",
    "\n",
    "# ---------- Container ----------\n",
    "row = widgets.HBox([start_idx_correlation, stop_idx_correlation],\n",
    "    layout=widgets.Layout(width=\"40%\", justify_content=\"space-between\", align_items=\"center\", padding=\"12px\", border=\"3px solid #444\", border_radius=\"10px\", background_color=\"#1e1e1e\"))\n",
    "\n",
    "row.layout.background_color = \"#1e1e1e\"\n",
    "row.layout.border = \"3px solid #444\"\n",
    "\n",
    "display(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = start_idx_correlation.value\n",
    "stop = stop_idx_correlation.value\n",
    "# ============================================================\n",
    "# Save voxel indices\n",
    "# ============================================================\n",
    "voxel_indices_seed = np.column_stack(np.where(var_seed))\n",
    "voxel_indices_mask = np.column_stack(np.where(var_mask))\n",
    "\n",
    "np.savetxt(\"roi_voxel_indices_seed.txt\", voxel_indices_seed, fmt=\"%d\")\n",
    "np.savetxt(\"roi_voxel_indices_mask.txt\", voxel_indices_mask, fmt=\"%d\")\n",
    "\n",
    "# ============================================================\n",
    "# Mean seed time series\n",
    "# ============================================================\n",
    "mean_ts_seed = ts_seed.mean(axis=1)\n",
    "np.savetxt(\"roi_mean_seed_timeseries.txt\", mean_ts_seed, fmt=\"%.6f\")\n",
    "\n",
    "# Debug slice\n",
    "np.savetxt(\"test.txt\", mean_ts_seed[start:stop])\n",
    "\n",
    "# ============================================================\n",
    "# Correlation computation (TIME DOMAIN)\n",
    "# ============================================================\n",
    "correlation_values = np.zeros((2, ts_mask.shape[1]), dtype=np.float32)\n",
    "\n",
    "x_ts = mean_ts_seed[start:stop]   # TIME series (length = stop-start)\n",
    "\n",
    "for col in range(ts_mask.shape[1]):\n",
    "    y_ts = ts_mask[start:stop, col]\n",
    "    r, p = scipy.stats.pearsonr(x_ts, y_ts)\n",
    "    correlation_values[0, col] = r\n",
    "    correlation_values[1, col] = p\n",
    "\n",
    "# ============================================================\n",
    "# FDR inputs\n",
    "# ============================================================\n",
    "rvals = correlation_values[0]\n",
    "pvals = correlation_values[1]\n",
    "\n",
    "# ============================================================\n",
    "# Fisher z-transform\n",
    "# ============================================================\n",
    "eps = np.finfo(np.float32).eps\n",
    "rvals_clipped = np.clip(rvals, -1 + eps, 1 - eps)\n",
    "zvals = np.arctanh(rvals_clipped)\n",
    "\n",
    "# ============================================================\n",
    "# Save EVERYTHING in one file\n",
    "# ============================================================\n",
    "out = np.column_stack((voxel_indices_mask, rvals, pvals, zvals))\n",
    "\n",
    "np.savetxt(\"seed_voxelwise_correlation.txt\", out, fmt=\"%d\\t%d\\t%d\\t%.6f\\t%.6e\\t%.6f\", header=\"x\\ty\\tz\\tr\\tp\\tz_fisher\")\n",
    "\n",
    "print(\"Rows written:\", out.shape[0])\n",
    "print(\"Mask voxels:\", np.sum(var_mask))\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- PLOTTING -------------------------------\n",
    "# ============================================================\n",
    "data = np.loadtxt(\"seed_voxelwise_correlation.txt\")\n",
    "# ---------------------------\n",
    "# Matplotlib style\n",
    "# ---------------------------\n",
    "plt.rcParams['font.family'] = ['serif']\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"axes.titlesize\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"legend.fontsize\"] = 12\n",
    "\n",
    "# ---------------------------\n",
    "# Data (VOXEL DOMAIN)\n",
    "# ---------------------------\n",
    "group_ids = data[:, 1].astype(int)   # voxel groups\n",
    "y_all     = data[:, 3]               # correlation coefficients\n",
    "\n",
    "assert y_all.shape[0] == group_ids.shape[0], \"Voxel data mismatch\"\n",
    "\n",
    "x_vox = np.arange(y_all.shape[0])    # voxel index axis\n",
    "unique_groups = np.unique(group_ids)\n",
    "\n",
    "# ---------------------------\n",
    "# Figure + GridSpec\n",
    "# ---------------------------\n",
    "fig = plt.figure(figsize=(24, 14))\n",
    "gs = GridSpec(nrows=3, ncols=8, height_ratios=[2.5, 1.5, 1.5], hspace=0.4)\n",
    "\n",
    "# ============================================================\n",
    "# Helper function: scatter by correlation range\n",
    "# ============================================================\n",
    "def scatter_by_range(ax, x, y):\n",
    "    mask_zero        = (y == 0)\n",
    "    mask_red         = (y > 0.5)  & (y <= 1.0)\n",
    "    mask_orange      = (y > 0.0)  & (y <= 0.5)\n",
    "    mask_greenyellow = (y >= -0.5) & (y < 0.0)\n",
    "    mask_blue        = (y >= -1.0) & (y < -0.5)\n",
    "\n",
    "    ax.scatter(x[mask_zero],        y[mask_zero],        color=\"black\",       s=18, label=\"0\")\n",
    "    ax.scatter(x[mask_red],         y[mask_red],         color=\"red\",         s=18, label=\"0.5 to 1.0\")\n",
    "    ax.scatter(x[mask_orange],      y[mask_orange],      color=\"orange\",      s=18, label=\"0 to 0.5\")\n",
    "    ax.scatter(x[mask_greenyellow], y[mask_greenyellow], color=\"greenyellow\", s=18, label=\"-0.5 to 0\")\n",
    "    ax.scatter(x[mask_blue],        y[mask_blue],        color=\"blue\",        s=18, label=\"-1 to -0.5\")\n",
    "\n",
    "# ============================================================\n",
    "# TOP: Combined plot (ALL voxels)\n",
    "# ============================================================\n",
    "ax_top = fig.add_subplot(gs[0, :])\n",
    "\n",
    "scatter_by_range(ax_top, x_vox, y_all)\n",
    "\n",
    "ax_top.set_title(\"Voxel-wise Correlation Coefficient — All Slices\")\n",
    "ax_top.set_ylabel(\"Correlation Coefficient\")\n",
    "ax_top.set_xlabel(\"Voxel Index\")\n",
    "\n",
    "handles, labels = ax_top.get_legend_handles_labels()\n",
    "ax_top.legend(handles, labels, ncol=5, frameon=False, loc=\"upper right\")\n",
    "\n",
    "# ============================================================\n",
    "# BOTTOM: Grouped subplots (8 × 2)\n",
    "# ============================================================\n",
    "for idx, g in enumerate(unique_groups[:16]):  # max 16 subplots\n",
    "    row = 1 + idx // 8\n",
    "    col = idx % 8\n",
    "\n",
    "    ax = fig.add_subplot(gs[row, col], sharex=ax_top, sharey=ax_top)\n",
    "\n",
    "    group_mask = (group_ids == g)\n",
    "    x_g = x_vox[group_mask]\n",
    "    y_g = y_all[group_mask]\n",
    "\n",
    "    scatter_by_range(ax, x_g, y_g)\n",
    "\n",
    "    ax.set_title(f\"group = {g}\", fontsize=12)\n",
    "\n",
    "    ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "    ax.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "# ---------------------------\n",
    "# Save figure\n",
    "# ---------------------------\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"corr_coeff_combined_and_grouped.svg\", dpi=1200)\n",
    "# plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "# Entering all data analysis record in the SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to a new SQlite database\n",
    "db_name = \"analysis_record_test.db\"\n",
    "db = os.path.join(root_location, db_name)\n",
    "conn = sqlite3.connect(db)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#drop old table if it exists\n",
    "# cursor.execute(\"DROP TABLE IF EXISTS Data_Analysis\")\n",
    "conn.commit()\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "# This is validation step, if any value is missing that indicates that the previous steps have not been successfully implemented. \n",
    "required_fields = {\n",
    "    \"analysis_done_by\": user,\n",
    "    \"root_location\": root_location,\n",
    "    \"subject_id\": subject_id,\n",
    "    \"analysis_folder_name\": folder_created,\n",
    "    \"functional_run\": func_scan_number,\n",
    "    \"structural_run\": struct_scan_number,\n",
    "    \"temporal_res\": tr,\n",
    "    \"window_duration\": win_entered.value,\n",
    "    \"spatial_smoothing\": fwhm_kernel,\n",
    "    \"spatial_smoothing_coreg_image\": fwhm_kernel_coregsitered,\n",
    "    \"roi_left\": roi_left,\n",
    "    \"mean_signal_change_left\": mean_signal_left,\n",
    "    \"roi_right\": roi_right,\n",
    "    \"mean_signal_change_right\": mean_signal_right,\n",
    "    \"start_idx_correlation\": start_idx_correlation.value,\n",
    "    \"end_idx_correlation\": stop_idx_correlation.value,\n",
    "}\n",
    "\n",
    "def validate_analysis_inputs(fields):\n",
    "    missing = [\n",
    "        name for name, value in fields.items()\n",
    "        if value is None or (isinstance(value, str) and value.strip() == \"\")\n",
    "    ]\n",
    "\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            \"Analysis NOT COMPLETE, Please run your complete pipeline for successful record.\\n\"\n",
    "            f\"Missing fields: {', '.join(missing)}\"\n",
    "        )\n",
    "\n",
    "    if tr <= 0:\n",
    "        raise RuntimeError(\"Invalid temporal resolution (TR must be > 0)\")\n",
    "\n",
    "    if win_entered.value <= 0:\n",
    "        raise RuntimeError(\"Invalid window duration\")\n",
    "\n",
    "    if start_idx_correlation.value >= stop_idx_correlation.value:\n",
    "        raise RuntimeError(\"Invalid correlation window indices\")\n",
    "\n",
    "# Run validation\n",
    "validate_analysis_inputs(required_fields)\n",
    "\n",
    "# Here we are creating the table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Data_Analysis (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    analysis_done_by TEXT,\n",
    "    root_location TEXT,\n",
    "    subject_id TEXT,\n",
    "    analysis_folder_name TEXT,\n",
    "    functional_run INTEGER,\n",
    "    structural_run INTEGER,\n",
    "    temporal_res REAL,\n",
    "    window_duration INTEGER,\n",
    "    spatial_smoothing REAL,\n",
    "    spatial_smoothing_coreg_image REAL,\n",
    "    roi_left TEXT,\n",
    "    mean_signal_change_left FLOAT,\n",
    "    roi_right TEXT,\n",
    "    mean_signal_change_right FLOAT,\n",
    "    start_idx_correlation INTEGER,\n",
    "    end_idx_correlation INTEGER,\n",
    "    created_at TEXT DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Based on the parameters used to analyse data throughout, enter them in the SQL database to create a record of what parameters were used for which data\n",
    "Data_Analysis = tuple(required_fields.values())\n",
    "cursor.execute(\"\"\"\n",
    "INSERT INTO Data_Analysis (analysis_done_by,root_location, subject_id, analysis_folder_name, functional_run, structural_run, temporal_res, window_duration, spatial_smoothing, \n",
    "               spatial_smoothing_coreg_image, roi_left, mean_signal_change_left, roi_right, mean_signal_change_right, start_idx_correlation, end_idx_correlation)\n",
    "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\", Data_Analysis)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get the print of the data that we entered\n",
    "df = pd.read_sql(\"SELECT * FROM Data_Analysis ORDER BY id DESC\", con=conn)\n",
    "display(df[df['analysis_done_by'] == user])\n",
    "\n",
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
